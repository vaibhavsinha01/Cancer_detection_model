{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (1.26.4)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp39-cp39-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp39-cp39-win_amd64.whl (11.2 MB)\n",
      "   ---------------------------------------- 0.0/11.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.2 MB 1.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.0/11.2 MB 1.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/11.2 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/11.2 MB 1.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 1.8/11.2 MB 1.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 2.1/11.2 MB 1.5 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.4/11.2 MB 1.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.2 MB 1.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.6/11.2 MB 1.4 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.1/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.1/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.4/11.2 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.7/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.2 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.5/11.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.7/11.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.0/11.2 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.2 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.2/11.2 MB 1.1 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.5/11.2 MB 1.1 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.2 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.0/11.2 MB 1.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.2 MB 1.1 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 6.6/11.2 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.8/11.2 MB 1.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.1/11.2 MB 1.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.3/11.2 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.6/11.2 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.9/11.2 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.1/11.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.2 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.9/11.2 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 9.2/11.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.2/11.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.2 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.2/11.2 MB 1.2 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/46.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/46.2 MB 799.2 kB/s eta 0:00:58\n",
      "    --------------------------------------- 0.8/46.2 MB 1.0 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 1.3/46.2 MB 1.3 MB/s eta 0:00:35\n",
      "   - -------------------------------------- 1.8/46.2 MB 1.5 MB/s eta 0:00:30\n",
      "   - -------------------------------------- 2.1/46.2 MB 1.6 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 2.4/46.2 MB 1.5 MB/s eta 0:00:30\n",
      "   -- ------------------------------------- 2.6/46.2 MB 1.4 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 2.9/46.2 MB 1.4 MB/s eta 0:00:31\n",
      "   -- ------------------------------------- 3.1/46.2 MB 1.4 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 3.7/46.2 MB 1.5 MB/s eta 0:00:29\n",
      "   --- ------------------------------------ 4.2/46.2 MB 1.6 MB/s eta 0:00:27\n",
      "   ---- ----------------------------------- 4.7/46.2 MB 1.6 MB/s eta 0:00:26\n",
      "   ---- ----------------------------------- 5.2/46.2 MB 1.7 MB/s eta 0:00:25\n",
      "   ---- ----------------------------------- 5.8/46.2 MB 1.8 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 6.0/46.2 MB 1.8 MB/s eta 0:00:23\n",
      "   ----- ---------------------------------- 6.6/46.2 MB 1.8 MB/s eta 0:00:23\n",
      "   ------ --------------------------------- 7.3/46.2 MB 1.9 MB/s eta 0:00:21\n",
      "   ------ --------------------------------- 7.9/46.2 MB 1.9 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 8.7/46.2 MB 2.0 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 9.4/46.2 MB 2.1 MB/s eta 0:00:18\n",
      "   -------- ------------------------------- 10.2/46.2 MB 2.2 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 10.7/46.2 MB 2.2 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 11.5/46.2 MB 2.2 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 12.6/46.2 MB 2.3 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 13.4/46.2 MB 2.4 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 13.9/46.2 MB 2.4 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 14.9/46.2 MB 2.5 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 15.7/46.2 MB 2.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 16.5/46.2 MB 2.6 MB/s eta 0:00:12\n",
      "   --------------- ------------------------ 17.6/46.2 MB 2.7 MB/s eta 0:00:11\n",
      "   ---------------- ----------------------- 19.4/46.2 MB 2.9 MB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 20.7/46.2 MB 3.0 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 21.8/46.2 MB 3.0 MB/s eta 0:00:09\n",
      "   -------------------- ------------------- 23.6/46.2 MB 3.2 MB/s eta 0:00:08\n",
      "   --------------------- ------------------ 24.9/46.2 MB 3.3 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 26.2/46.2 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 27.8/46.2 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 29.6/46.2 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 31.5/46.2 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 33.3/46.2 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 34.6/46.2 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 37.0/46.2 MB 4.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 39.1/46.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 40.4/46.2 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 41.9/46.2 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 44.8/46.2 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  46.1/46.2 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 46.2/46.2 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.13.1 threadpoolctl-3.6.0\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-2.1.4-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Using cached xgboost-2.1.4-py3-none-win_amd64.whl (124.9 MB)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.4\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.69.0)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.13.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.14.1-cp39-cp39-win_amd64.whl.metadata (50 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.19.0-cp39-cp39-win_amd64.whl (375.7 MB)\n",
      "   ---------------------------------------- 0.0/375.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/375.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/375.7 MB 2.4 MB/s eta 0:02:38\n",
      "   ---------------------------------------- 0.8/375.7 MB 2.2 MB/s eta 0:02:49\n",
      "   ---------------------------------------- 1.3/375.7 MB 1.9 MB/s eta 0:03:16\n",
      "   ---------------------------------------- 1.6/375.7 MB 2.0 MB/s eta 0:03:12\n",
      "   ---------------------------------------- 2.1/375.7 MB 1.8 MB/s eta 0:03:27\n",
      "   ---------------------------------------- 2.4/375.7 MB 1.8 MB/s eta 0:03:24\n",
      "   ---------------------------------------- 2.9/375.7 MB 1.9 MB/s eta 0:03:18\n",
      "   ---------------------------------------- 3.4/375.7 MB 2.0 MB/s eta 0:03:09\n",
      "   ---------------------------------------- 3.9/375.7 MB 2.0 MB/s eta 0:03:06\n",
      "   ---------------------------------------- 4.5/375.7 MB 2.0 MB/s eta 0:03:03\n",
      "    --------------------------------------- 5.0/375.7 MB 2.1 MB/s eta 0:02:55\n",
      "    --------------------------------------- 5.5/375.7 MB 2.2 MB/s eta 0:02:53\n",
      "    --------------------------------------- 5.8/375.7 MB 2.1 MB/s eta 0:02:56\n",
      "    --------------------------------------- 6.3/375.7 MB 2.2 MB/s eta 0:02:51\n",
      "    --------------------------------------- 7.1/375.7 MB 2.2 MB/s eta 0:02:45\n",
      "    --------------------------------------- 7.9/375.7 MB 2.3 MB/s eta 0:02:40\n",
      "    --------------------------------------- 8.4/375.7 MB 2.3 MB/s eta 0:02:37\n",
      "    --------------------------------------- 8.9/375.7 MB 2.3 MB/s eta 0:02:38\n",
      "   - -------------------------------------- 9.7/375.7 MB 2.4 MB/s eta 0:02:33\n",
      "   - -------------------------------------- 10.2/375.7 MB 2.4 MB/s eta 0:02:31\n",
      "   - -------------------------------------- 10.7/375.7 MB 2.4 MB/s eta 0:02:32\n",
      "   - -------------------------------------- 11.0/375.7 MB 2.4 MB/s eta 0:02:31\n",
      "   - -------------------------------------- 11.8/375.7 MB 2.5 MB/s eta 0:02:28\n",
      "   - -------------------------------------- 12.8/375.7 MB 2.5 MB/s eta 0:02:24\n",
      "   - -------------------------------------- 13.6/375.7 MB 2.6 MB/s eta 0:02:21\n",
      "   - -------------------------------------- 14.2/375.7 MB 2.6 MB/s eta 0:02:20\n",
      "   - -------------------------------------- 14.9/375.7 MB 2.6 MB/s eta 0:02:17\n",
      "   - -------------------------------------- 16.0/375.7 MB 2.7 MB/s eta 0:02:13\n",
      "   - -------------------------------------- 16.5/375.7 MB 2.7 MB/s eta 0:02:12\n",
      "   - -------------------------------------- 17.3/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   - -------------------------------------- 17.8/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   - -------------------------------------- 18.4/375.7 MB 2.8 MB/s eta 0:02:10\n",
      "   -- ------------------------------------- 18.9/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   -- ------------------------------------- 19.4/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   -- ------------------------------------- 19.9/375.7 MB 2.8 MB/s eta 0:02:09\n",
      "   -- ------------------------------------- 20.4/375.7 MB 2.7 MB/s eta 0:02:10\n",
      "   -- ------------------------------------- 21.0/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   -- ------------------------------------- 21.5/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   -- ------------------------------------- 22.0/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   -- ------------------------------------- 22.5/375.7 MB 2.7 MB/s eta 0:02:11\n",
      "   -- ------------------------------------- 23.3/375.7 MB 2.7 MB/s eta 0:02:10\n",
      "   -- ------------------------------------- 23.9/375.7 MB 2.7 MB/s eta 0:02:10\n",
      "   -- ------------------------------------- 24.4/375.7 MB 2.7 MB/s eta 0:02:09\n",
      "   -- ------------------------------------- 25.2/375.7 MB 2.7 MB/s eta 0:02:08\n",
      "   -- ------------------------------------- 25.7/375.7 MB 2.7 MB/s eta 0:02:08\n",
      "   -- ------------------------------------- 26.0/375.7 MB 2.7 MB/s eta 0:02:08\n",
      "   -- ------------------------------------- 26.7/375.7 MB 2.7 MB/s eta 0:02:09\n",
      "   -- ------------------------------------- 27.0/375.7 MB 2.7 MB/s eta 0:02:08\n",
      "   -- ------------------------------------- 27.8/375.7 MB 2.7 MB/s eta 0:02:08\n",
      "   --- ------------------------------------ 28.6/375.7 MB 2.7 MB/s eta 0:02:08\n",
      "   --- ------------------------------------ 29.4/375.7 MB 2.8 MB/s eta 0:02:06\n",
      "   --- ------------------------------------ 30.1/375.7 MB 2.8 MB/s eta 0:02:05\n",
      "   --- ------------------------------------ 30.9/375.7 MB 2.8 MB/s eta 0:02:04\n",
      "   --- ------------------------------------ 31.5/375.7 MB 2.8 MB/s eta 0:02:03\n",
      "   --- ------------------------------------ 32.2/375.7 MB 2.8 MB/s eta 0:02:03\n",
      "   --- ------------------------------------ 33.0/375.7 MB 2.8 MB/s eta 0:02:02\n",
      "   --- ------------------------------------ 34.1/375.7 MB 2.9 MB/s eta 0:02:00\n",
      "   --- ------------------------------------ 34.9/375.7 MB 2.9 MB/s eta 0:01:59\n",
      "   --- ------------------------------------ 35.7/375.7 MB 2.9 MB/s eta 0:01:58\n",
      "   --- ------------------------------------ 36.7/375.7 MB 2.9 MB/s eta 0:01:56\n",
      "   ---- ----------------------------------- 37.7/375.7 MB 3.0 MB/s eta 0:01:55\n",
      "   ---- ----------------------------------- 38.5/375.7 MB 3.0 MB/s eta 0:01:54\n",
      "   ---- ----------------------------------- 39.3/375.7 MB 3.0 MB/s eta 0:01:53\n",
      "   ---- ----------------------------------- 39.8/375.7 MB 3.0 MB/s eta 0:01:53\n",
      "   ---- ----------------------------------- 40.9/375.7 MB 3.0 MB/s eta 0:01:52\n",
      "   ---- ----------------------------------- 41.7/375.7 MB 3.0 MB/s eta 0:01:51\n",
      "   ---- ----------------------------------- 42.2/375.7 MB 3.0 MB/s eta 0:01:51\n",
      "   ---- ----------------------------------- 43.0/375.7 MB 3.0 MB/s eta 0:01:51\n",
      "   ---- ----------------------------------- 44.0/375.7 MB 3.1 MB/s eta 0:01:49\n",
      "   ---- ----------------------------------- 45.1/375.7 MB 3.1 MB/s eta 0:01:47\n",
      "   ---- ----------------------------------- 46.1/375.7 MB 3.1 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 46.7/375.7 MB 3.1 MB/s eta 0:01:46\n",
      "   ----- ---------------------------------- 47.7/375.7 MB 3.1 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 48.2/375.7 MB 3.1 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 48.8/375.7 MB 3.1 MB/s eta 0:01:46\n",
      "   ----- ---------------------------------- 49.5/375.7 MB 3.1 MB/s eta 0:01:45\n",
      "   ----- ---------------------------------- 50.9/375.7 MB 3.1 MB/s eta 0:01:44\n",
      "   ----- ---------------------------------- 51.6/375.7 MB 3.2 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 52.7/375.7 MB 3.2 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 53.5/375.7 MB 3.2 MB/s eta 0:01:41\n",
      "   ----- ---------------------------------- 54.3/375.7 MB 3.2 MB/s eta 0:01:41\n",
      "   ----- ---------------------------------- 55.1/375.7 MB 3.2 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 55.8/375.7 MB 3.2 MB/s eta 0:01:40\n",
      "   ------ --------------------------------- 56.4/375.7 MB 3.2 MB/s eta 0:01:40\n",
      "   ------ --------------------------------- 57.1/375.7 MB 3.2 MB/s eta 0:01:40\n",
      "   ------ --------------------------------- 57.7/375.7 MB 3.2 MB/s eta 0:01:39\n",
      "   ------ --------------------------------- 58.7/375.7 MB 3.2 MB/s eta 0:01:39\n",
      "   ------ --------------------------------- 59.8/375.7 MB 3.2 MB/s eta 0:01:38\n",
      "   ------ --------------------------------- 60.6/375.7 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 61.6/375.7 MB 3.3 MB/s eta 0:01:37\n",
      "   ------ --------------------------------- 62.4/375.7 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 63.2/375.7 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 64.0/375.7 MB 3.3 MB/s eta 0:01:36\n",
      "   ------ --------------------------------- 64.5/375.7 MB 3.3 MB/s eta 0:01:35\n",
      "   ------ --------------------------------- 65.3/375.7 MB 3.3 MB/s eta 0:01:35\n",
      "   ------- -------------------------------- 66.3/375.7 MB 3.3 MB/s eta 0:01:34\n",
      "   ------- -------------------------------- 67.4/375.7 MB 3.3 MB/s eta 0:01:33\n",
      "   ------- -------------------------------- 68.2/375.7 MB 3.3 MB/s eta 0:01:33\n",
      "   ------- -------------------------------- 69.2/375.7 MB 3.3 MB/s eta 0:01:32\n",
      "   ------- -------------------------------- 70.5/375.7 MB 3.4 MB/s eta 0:01:31\n",
      "   ------- -------------------------------- 71.6/375.7 MB 3.4 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 72.6/375.7 MB 3.4 MB/s eta 0:01:30\n",
      "   ------- -------------------------------- 73.9/375.7 MB 3.4 MB/s eta 0:01:29\n",
      "   ------- -------------------------------- 74.7/375.7 MB 3.4 MB/s eta 0:01:28\n",
      "   -------- ------------------------------- 75.5/375.7 MB 3.4 MB/s eta 0:01:28\n",
      "   -------- ------------------------------- 76.0/375.7 MB 3.4 MB/s eta 0:01:28\n",
      "   -------- ------------------------------- 76.5/375.7 MB 3.4 MB/s eta 0:01:28\n",
      "   -------- ------------------------------- 77.3/375.7 MB 3.4 MB/s eta 0:01:27\n",
      "   -------- ------------------------------- 78.1/375.7 MB 3.4 MB/s eta 0:01:28\n",
      "   -------- ------------------------------- 78.9/375.7 MB 3.4 MB/s eta 0:01:27\n",
      "   -------- ------------------------------- 79.7/375.7 MB 3.4 MB/s eta 0:01:27\n",
      "   -------- ------------------------------- 80.2/375.7 MB 3.4 MB/s eta 0:01:27\n",
      "   -------- ------------------------------- 81.0/375.7 MB 3.4 MB/s eta 0:01:26\n",
      "   -------- ------------------------------- 81.5/375.7 MB 3.4 MB/s eta 0:01:26\n",
      "   -------- ------------------------------- 81.8/375.7 MB 3.4 MB/s eta 0:01:27\n",
      "   -------- ------------------------------- 82.3/375.7 MB 3.4 MB/s eta 0:01:27\n",
      "   -------- ------------------------------- 83.4/375.7 MB 3.4 MB/s eta 0:01:26\n",
      "   -------- ------------------------------- 83.9/375.7 MB 3.4 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 84.9/375.7 MB 3.4 MB/s eta 0:01:26\n",
      "   --------- ------------------------------ 86.0/375.7 MB 3.4 MB/s eta 0:01:25\n",
      "   --------- ------------------------------ 86.8/375.7 MB 3.4 MB/s eta 0:01:25\n",
      "   --------- ------------------------------ 87.6/375.7 MB 3.4 MB/s eta 0:01:25\n",
      "   --------- ------------------------------ 88.1/375.7 MB 3.4 MB/s eta 0:01:25\n",
      "   --------- ------------------------------ 88.9/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 89.7/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 90.2/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 91.0/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 91.5/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 91.8/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 92.5/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 93.1/375.7 MB 3.4 MB/s eta 0:01:24\n",
      "   --------- ------------------------------ 93.8/375.7 MB 3.4 MB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 94.6/375.7 MB 3.4 MB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 95.4/375.7 MB 3.4 MB/s eta 0:01:23\n",
      "   ---------- ----------------------------- 96.5/375.7 MB 3.4 MB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 96.7/375.7 MB 3.4 MB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 97.5/375.7 MB 3.4 MB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 98.6/375.7 MB 3.4 MB/s eta 0:01:22\n",
      "   ---------- ----------------------------- 99.6/375.7 MB 3.4 MB/s eta 0:01:21\n",
      "   ---------- ----------------------------- 100.4/375.7 MB 3.4 MB/s eta 0:01:21\n",
      "   ---------- ----------------------------- 101.4/375.7 MB 3.4 MB/s eta 0:01:20\n",
      "   ---------- ----------------------------- 102.8/375.7 MB 3.5 MB/s eta 0:01:19\n",
      "   ----------- ---------------------------- 103.8/375.7 MB 3.5 MB/s eta 0:01:19\n",
      "   ----------- ---------------------------- 104.6/375.7 MB 3.5 MB/s eta 0:01:18\n",
      "   ----------- ---------------------------- 105.6/375.7 MB 3.5 MB/s eta 0:01:18\n",
      "   ----------- ---------------------------- 106.4/375.7 MB 3.5 MB/s eta 0:01:17\n",
      "   ----------- ---------------------------- 107.2/375.7 MB 3.5 MB/s eta 0:01:17\n",
      "   ----------- ---------------------------- 108.0/375.7 MB 3.5 MB/s eta 0:01:16\n",
      "   ----------- ---------------------------- 108.8/375.7 MB 3.6 MB/s eta 0:01:16\n",
      "   ----------- ---------------------------- 109.3/375.7 MB 3.6 MB/s eta 0:01:15\n",
      "   ----------- ---------------------------- 110.1/375.7 MB 3.6 MB/s eta 0:01:15\n",
      "   ----------- ---------------------------- 110.9/375.7 MB 3.6 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 111.7/375.7 MB 3.6 MB/s eta 0:01:14\n",
      "   ----------- ---------------------------- 112.5/375.7 MB 3.6 MB/s eta 0:01:14\n",
      "   ------------ --------------------------- 113.5/375.7 MB 3.6 MB/s eta 0:01:13\n",
      "   ------------ --------------------------- 114.0/375.7 MB 3.6 MB/s eta 0:01:13\n",
      "   ------------ --------------------------- 115.1/375.7 MB 3.6 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 116.1/375.7 MB 3.6 MB/s eta 0:01:12\n",
      "   ------------ --------------------------- 116.9/375.7 MB 3.7 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 118.2/375.7 MB 3.7 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 119.3/375.7 MB 3.7 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 120.1/375.7 MB 3.7 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 121.1/375.7 MB 3.7 MB/s eta 0:01:09\n",
      "   ------------ --------------------------- 121.6/375.7 MB 3.7 MB/s eta 0:01:09\n",
      "   ------------- -------------------------- 122.2/375.7 MB 3.7 MB/s eta 0:01:09\n",
      "   ------------- -------------------------- 122.7/375.7 MB 3.7 MB/s eta 0:01:09\n",
      "   ------------- -------------------------- 123.5/375.7 MB 3.7 MB/s eta 0:01:08\n",
      "   ------------- -------------------------- 124.5/375.7 MB 3.7 MB/s eta 0:01:08\n",
      "   ------------- -------------------------- 125.3/375.7 MB 3.7 MB/s eta 0:01:08\n",
      "   ------------- -------------------------- 126.1/375.7 MB 3.7 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 126.6/375.7 MB 3.7 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 127.4/375.7 MB 3.7 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 128.2/375.7 MB 3.7 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 129.0/375.7 MB 3.7 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 129.8/375.7 MB 3.7 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 130.3/375.7 MB 3.7 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 131.1/375.7 MB 3.7 MB/s eta 0:01:06\n",
      "   -------------- ------------------------- 131.6/375.7 MB 3.7 MB/s eta 0:01:06\n",
      "   -------------- ------------------------- 132.4/375.7 MB 3.7 MB/s eta 0:01:06\n",
      "   -------------- ------------------------- 133.2/375.7 MB 3.8 MB/s eta 0:01:05\n",
      "   -------------- ------------------------- 134.2/375.7 MB 3.8 MB/s eta 0:01:05\n",
      "   -------------- ------------------------- 135.0/375.7 MB 3.8 MB/s eta 0:01:04\n",
      "   -------------- ------------------------- 135.8/375.7 MB 3.8 MB/s eta 0:01:04\n",
      "   -------------- ------------------------- 136.6/375.7 MB 3.8 MB/s eta 0:01:04\n",
      "   -------------- ------------------------- 137.4/375.7 MB 3.8 MB/s eta 0:01:03\n",
      "   -------------- ------------------------- 137.9/375.7 MB 3.8 MB/s eta 0:01:03\n",
      "   -------------- ------------------------- 138.7/375.7 MB 3.8 MB/s eta 0:01:03\n",
      "   -------------- ------------------------- 139.2/375.7 MB 3.8 MB/s eta 0:01:03\n",
      "   -------------- ------------------------- 140.0/375.7 MB 3.8 MB/s eta 0:01:02\n",
      "   -------------- ------------------------- 140.8/375.7 MB 3.8 MB/s eta 0:01:02\n",
      "   --------------- ------------------------ 141.8/375.7 MB 3.8 MB/s eta 0:01:02\n",
      "   --------------- ------------------------ 142.3/375.7 MB 3.8 MB/s eta 0:01:01\n",
      "   --------------- ------------------------ 143.1/375.7 MB 3.8 MB/s eta 0:01:01\n",
      "   --------------- ------------------------ 144.2/375.7 MB 3.9 MB/s eta 0:01:01\n",
      "   --------------- ------------------------ 144.7/375.7 MB 3.8 MB/s eta 0:01:01\n",
      "   --------------- ------------------------ 145.5/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   --------------- ------------------------ 146.3/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   --------------- ------------------------ 147.1/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   --------------- ------------------------ 147.8/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   --------------- ------------------------ 148.4/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   --------------- ------------------------ 148.6/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   --------------- ------------------------ 149.4/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   --------------- ------------------------ 149.7/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 150.5/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 151.0/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 151.5/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 152.0/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 152.6/375.7 MB 3.8 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 153.1/375.7 MB 3.7 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 153.4/375.7 MB 3.7 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 153.9/375.7 MB 3.7 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 154.4/375.7 MB 3.7 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 154.9/375.7 MB 3.7 MB/s eta 0:01:00\n",
      "   ---------------- ----------------------- 155.5/375.7 MB 3.7 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 155.7/375.7 MB 3.7 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 156.0/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 156.2/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 156.8/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 157.5/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 158.1/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 158.9/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 159.4/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ---------------- ----------------------- 159.6/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 160.2/375.7 MB 3.6 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 160.7/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 161.2/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 161.7/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 162.3/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 163.1/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 163.6/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 164.4/375.7 MB 3.5 MB/s eta 0:01:00\n",
      "   ----------------- ---------------------- 164.9/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 165.4/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 165.7/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 166.2/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 167.0/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 167.5/375.7 MB 3.5 MB/s eta 0:01:01\n",
      "   ----------------- ---------------------- 168.3/375.7 MB 3.5 MB/s eta 0:01:00\n",
      "   ----------------- ---------------------- 168.8/375.7 MB 3.5 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 169.3/375.7 MB 3.4 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 170.1/375.7 MB 3.4 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 170.9/375.7 MB 3.4 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 171.4/375.7 MB 3.4 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 171.7/375.7 MB 3.4 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 172.5/375.7 MB 3.4 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 173.3/375.7 MB 3.4 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 173.8/375.7 MB 3.3 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 174.3/375.7 MB 3.3 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 174.9/375.7 MB 3.3 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 175.6/375.7 MB 3.3 MB/s eta 0:01:01\n",
      "   ------------------ --------------------- 176.4/375.7 MB 3.3 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 176.7/375.7 MB 3.3 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 177.5/375.7 MB 3.3 MB/s eta 0:01:00\n",
      "   ------------------ --------------------- 177.7/375.7 MB 3.3 MB/s eta 0:01:00\n",
      "   ------------------- -------------------- 178.5/375.7 MB 3.3 MB/s eta 0:01:00\n",
      "   ------------------- -------------------- 179.0/375.7 MB 3.3 MB/s eta 0:01:00\n",
      "   ------------------- -------------------- 180.1/375.7 MB 3.3 MB/s eta 0:01:00\n",
      "   ------------------- -------------------- 180.9/375.7 MB 3.3 MB/s eta 0:00:59\n",
      "   ------------------- -------------------- 181.7/375.7 MB 3.3 MB/s eta 0:00:59\n",
      "   ------------------- -------------------- 182.7/375.7 MB 3.4 MB/s eta 0:00:58\n",
      "   ------------------- -------------------- 184.0/375.7 MB 3.4 MB/s eta 0:00:57\n",
      "   ------------------- -------------------- 184.8/375.7 MB 3.4 MB/s eta 0:00:57\n",
      "   ------------------- -------------------- 185.6/375.7 MB 3.4 MB/s eta 0:00:57\n",
      "   ------------------- -------------------- 186.9/375.7 MB 3.4 MB/s eta 0:00:56\n",
      "   ------------------- -------------------- 187.4/375.7 MB 3.4 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 188.7/375.7 MB 3.4 MB/s eta 0:00:56\n",
      "   -------------------- ------------------- 189.5/375.7 MB 3.4 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 190.8/375.7 MB 3.4 MB/s eta 0:00:55\n",
      "   -------------------- ------------------- 191.9/375.7 MB 3.4 MB/s eta 0:00:54\n",
      "   -------------------- ------------------- 192.9/375.7 MB 3.4 MB/s eta 0:00:54\n",
      "   -------------------- ------------------- 194.5/375.7 MB 3.5 MB/s eta 0:00:53\n",
      "   -------------------- ------------------- 196.1/375.7 MB 3.5 MB/s eta 0:00:52\n",
      "   --------------------- ------------------ 197.4/375.7 MB 3.5 MB/s eta 0:00:51\n",
      "   --------------------- ------------------ 199.2/375.7 MB 3.6 MB/s eta 0:00:50\n",
      "   --------------------- ------------------ 200.8/375.7 MB 3.6 MB/s eta 0:00:49\n",
      "   --------------------- ------------------ 202.4/375.7 MB 3.6 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 204.2/375.7 MB 3.7 MB/s eta 0:00:47\n",
      "   --------------------- ------------------ 205.3/375.7 MB 3.7 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 207.4/375.7 MB 3.7 MB/s eta 0:00:46\n",
      "   ---------------------- ----------------- 210.2/375.7 MB 3.8 MB/s eta 0:00:44\n",
      "   ---------------------- ----------------- 211.8/375.7 MB 3.8 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 213.6/375.7 MB 3.8 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 215.7/375.7 MB 3.9 MB/s eta 0:00:42\n",
      "   ----------------------- ---------------- 218.9/375.7 MB 3.9 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 220.2/375.7 MB 4.0 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 222.8/375.7 MB 4.0 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 224.4/375.7 MB 4.0 MB/s eta 0:00:38\n",
      "   ------------------------ --------------- 225.7/375.7 MB 4.0 MB/s eta 0:00:38\n",
      "   ------------------------ --------------- 227.8/375.7 MB 4.1 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 229.9/375.7 MB 4.1 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 231.7/375.7 MB 4.2 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 233.8/375.7 MB 4.2 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 235.1/375.7 MB 4.2 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 236.2/375.7 MB 4.2 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 238.3/375.7 MB 4.3 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 239.9/375.7 MB 4.3 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 241.2/375.7 MB 4.3 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 242.7/375.7 MB 4.3 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 244.6/375.7 MB 4.4 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 247.2/375.7 MB 4.4 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 249.0/375.7 MB 4.5 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 251.1/375.7 MB 4.5 MB/s eta 0:00:28\n",
      "   -------------------------- ------------- 253.2/375.7 MB 4.6 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 255.6/375.7 MB 4.6 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 257.9/375.7 MB 4.6 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 259.8/375.7 MB 4.7 MB/s eta 0:00:25\n",
      "   --------------------------- ------------ 261.6/375.7 MB 4.7 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 263.7/375.7 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 265.3/375.7 MB 4.8 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 267.1/375.7 MB 4.8 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 268.2/375.7 MB 4.8 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 270.0/375.7 MB 4.9 MB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 271.6/375.7 MB 4.9 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 273.4/375.7 MB 4.9 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 275.3/375.7 MB 5.0 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 276.8/375.7 MB 5.0 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 278.1/375.7 MB 5.0 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 279.4/375.7 MB 5.0 MB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 280.8/375.7 MB 5.0 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 282.1/375.7 MB 5.1 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 283.1/375.7 MB 5.1 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 284.2/375.7 MB 5.1 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 286.0/375.7 MB 5.1 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 287.8/375.7 MB 5.2 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 289.7/375.7 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 291.2/375.7 MB 5.2 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 292.8/375.7 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 293.6/375.7 MB 5.2 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 294.6/375.7 MB 5.3 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 295.7/375.7 MB 5.3 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 296.7/375.7 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 297.5/375.7 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 298.1/375.7 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 298.8/375.7 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------------------------- -------- 299.9/375.7 MB 5.3 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 300.7/375.7 MB 5.3 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 301.5/375.7 MB 5.3 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 302.0/375.7 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 303.0/375.7 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 304.1/375.7 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 305.1/375.7 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 305.9/375.7 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 306.7/375.7 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 308.0/375.7 MB 5.3 MB/s eta 0:00:13\n",
      "   -------------------------------- ------- 309.3/375.7 MB 5.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 310.1/375.7 MB 5.4 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 311.4/375.7 MB 5.4 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 313.0/375.7 MB 5.4 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 314.3/375.7 MB 5.4 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 315.6/375.7 MB 5.5 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 316.9/375.7 MB 5.5 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 318.0/375.7 MB 5.5 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 319.3/375.7 MB 5.6 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 320.3/375.7 MB 5.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 321.1/375.7 MB 5.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 322.4/375.7 MB 5.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 323.7/375.7 MB 5.6 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 324.8/375.7 MB 5.7 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 326.1/375.7 MB 5.7 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 327.4/375.7 MB 5.7 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 328.2/375.7 MB 5.7 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 329.3/375.7 MB 5.8 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 330.0/375.7 MB 5.8 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 331.4/375.7 MB 5.8 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 332.7/375.7 MB 5.8 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 333.4/375.7 MB 5.8 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 334.5/375.7 MB 5.8 MB/s eta 0:00:08\n",
      "   ----------------------------------- ---- 335.0/375.7 MB 5.8 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 335.8/375.7 MB 5.8 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 336.6/375.7 MB 5.8 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 337.4/375.7 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 338.2/375.7 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 339.2/375.7 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 340.3/375.7 MB 5.9 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 341.3/375.7 MB 5.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 342.1/375.7 MB 5.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 343.1/375.7 MB 5.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 343.7/375.7 MB 5.9 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 345.0/375.7 MB 6.0 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 346.0/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 346.8/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 347.9/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 348.4/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 348.7/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 349.2/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 349.7/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 350.2/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 350.7/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 351.0/375.7 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 351.3/375.7 MB 5.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 351.8/375.7 MB 5.9 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 352.3/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 352.8/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 353.1/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 353.6/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 354.2/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 354.4/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 354.7/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 355.2/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 355.5/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 356.0/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 356.3/375.7 MB 5.9 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 356.8/375.7 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 357.0/375.7 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 357.6/375.7 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 357.8/375.7 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 358.4/375.7 MB 5.8 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 358.6/375.7 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 358.9/375.7 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 359.4/375.7 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 359.9/375.7 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 360.2/375.7 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 360.7/375.7 MB 5.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 361.0/375.7 MB 5.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 361.2/375.7 MB 5.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 361.8/375.7 MB 5.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 362.0/375.7 MB 5.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 362.5/375.7 MB 5.5 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 362.8/375.7 MB 5.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 363.3/375.7 MB 5.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 363.6/375.7 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 364.1/375.7 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 364.4/375.7 MB 5.3 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 364.9/375.7 MB 5.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 365.4/375.7 MB 5.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 366.0/375.7 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  366.5/375.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------------------------------  367.0/375.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  367.3/375.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  367.8/375.7 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.1/375.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.6/375.7 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.8/375.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.4/375.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.6/375.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  369.9/375.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------------------------  370.4/375.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  370.9/375.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  371.2/375.7 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------------------------  371.7/375.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  372.2/375.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  372.8/375.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.3/375.7 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.8/375.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.3/375.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.9/375.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.7/375.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 375.7/375.7 MB 3.9 MB/s eta 0:00:00\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.13.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.3/3.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.8/3.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.6/3.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 3.8 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.5/1.3 MB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.0/1.3 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 2.4 MB/s eta 0:00:00\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Downloading ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl (209 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.8/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.3/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.1/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.9/5.5 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 3.4/5.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.3/1.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.0-py3-none-any.whl (6.3 kB)\n",
      "Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp39-cp39-win_amd64.whl (291 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, optree, opt-einsum, ml-dtypes, h5py, google-pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 h5py-3.13.0 keras-3.9.1 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.19.0 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.0.0 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install xgboost\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     worst smoothness  worst compactness  worst concavity  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
      "0                  0.2654          0.4601                  0.11890       0  \n",
      "1                  0.1860          0.2750                  0.08902       0  \n",
      "2                  0.2430          0.3613                  0.08758       0  \n",
      "3                  0.2575          0.6638                  0.17300       0  \n",
      "4                  0.1625          0.2364                  0.07678       0  \n",
      "..                    ...             ...                      ...     ...  \n",
      "564                0.2216          0.2060                  0.07115       0  \n",
      "565                0.1628          0.2572                  0.06637       0  \n",
      "566                0.1418          0.2218                  0.07820       0  \n",
      "567                0.2650          0.4087                  0.12400       0  \n",
      "568                0.0000          0.2871                  0.07039       1  \n",
      "\n",
      "[569 rows x 31 columns]\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vaibh\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7419 - loss: 0.5092 - val_accuracy: 0.9649 - val_loss: 0.1233\n",
      "Epoch 2/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9428 - loss: 0.1541 - val_accuracy: 0.9825 - val_loss: 0.0866\n",
      "Epoch 3/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9743 - loss: 0.0815 - val_accuracy: 0.9474 - val_loss: 0.1040\n",
      "Epoch 4/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.0760 - val_accuracy: 0.9474 - val_loss: 0.0893\n",
      "Epoch 5/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9755 - loss: 0.0590 - val_accuracy: 0.9737 - val_loss: 0.0805\n",
      "Epoch 6/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0577 - val_accuracy: 0.9825 - val_loss: 0.0674\n",
      "Epoch 7/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0900 - val_accuracy: 0.9737 - val_loss: 0.0892\n",
      "Epoch 8/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0423 - val_accuracy: 0.9737 - val_loss: 0.0665\n",
      "Epoch 9/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0588 - val_accuracy: 0.9649 - val_loss: 0.0855\n",
      "Epoch 10/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0373 - val_accuracy: 0.9649 - val_loss: 0.0988\n",
      "Epoch 11/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0406 - val_accuracy: 0.9649 - val_loss: 0.0920\n",
      "Epoch 12/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0301 - val_accuracy: 0.9737 - val_loss: 0.0776\n",
      "Epoch 13/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0260 - val_accuracy: 0.9649 - val_loss: 0.0986\n",
      "Epoch 14/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0366 - val_accuracy: 0.9737 - val_loss: 0.0674\n",
      "Epoch 15/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0477 - val_accuracy: 0.9737 - val_loss: 0.0816\n",
      "Epoch 16/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0229 - val_accuracy: 0.9912 - val_loss: 0.0669\n",
      "Epoch 17/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0299 - val_accuracy: 0.9912 - val_loss: 0.0678\n",
      "Epoch 18/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0239 - val_accuracy: 0.9825 - val_loss: 0.0796\n",
      "Epoch 19/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0229 - val_accuracy: 0.9649 - val_loss: 0.0804\n",
      "Epoch 20/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0263 - val_accuracy: 0.9649 - val_loss: 0.1042\n",
      "Epoch 21/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0209 - val_accuracy: 0.9912 - val_loss: 0.0385\n",
      "Epoch 22/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0565 - val_accuracy: 0.9474 - val_loss: 0.1407\n",
      "Epoch 23/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0228 - val_accuracy: 0.9825 - val_loss: 0.0897\n",
      "Epoch 24/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0156 - val_accuracy: 0.9825 - val_loss: 0.1086\n",
      "Epoch 25/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0108 - val_accuracy: 0.9825 - val_loss: 0.0959\n",
      "Epoch 26/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0430 - val_accuracy: 0.9825 - val_loss: 0.0775\n",
      "Epoch 27/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0174 - val_accuracy: 0.9825 - val_loss: 0.0917\n",
      "Epoch 28/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0211 - val_accuracy: 0.9825 - val_loss: 0.0772\n",
      "Epoch 29/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0126 - val_accuracy: 0.9825 - val_loss: 0.0864\n",
      "Epoch 30/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0096 - val_accuracy: 0.9825 - val_loss: 0.0594\n",
      "Epoch 31/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0082 - val_accuracy: 0.9825 - val_loss: 0.1020\n",
      "Epoch 32/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0090 - val_accuracy: 0.9825 - val_loss: 0.1019\n",
      "Epoch 33/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0129 - val_accuracy: 0.9825 - val_loss: 0.1028\n",
      "Epoch 34/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0069 - val_accuracy: 0.9825 - val_loss: 0.0847\n",
      "Epoch 35/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0124 - val_accuracy: 0.9825 - val_loss: 0.0937\n",
      "Epoch 36/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9912 - val_loss: 0.0812\n",
      "Epoch 37/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0105 - val_accuracy: 0.9386 - val_loss: 0.1547\n",
      "Epoch 38/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.9737 - val_loss: 0.1196\n",
      "Epoch 39/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0083 - val_accuracy: 0.9825 - val_loss: 0.1351\n",
      "Epoch 40/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9649 - val_loss: 0.1671\n",
      "Epoch 41/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0144 - val_accuracy: 0.9825 - val_loss: 0.1468\n",
      "Epoch 42/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0060 - val_accuracy: 0.9825 - val_loss: 0.1031\n",
      "Epoch 43/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9825 - val_loss: 0.1083\n",
      "Epoch 44/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9737 - val_loss: 0.1397\n",
      "Epoch 45/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9386 - val_loss: 0.1970\n",
      "Epoch 46/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0119 - val_accuracy: 0.9825 - val_loss: 0.1429\n",
      "Epoch 47/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0049 - val_accuracy: 0.9649 - val_loss: 0.1637\n",
      "Epoch 48/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0267 - val_accuracy: 0.9649 - val_loss: 0.2108\n",
      "Epoch 49/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.9649 - val_loss: 0.2099\n",
      "Epoch 50/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9649 - val_loss: 0.2212\n",
      "Epoch 51/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0116 - val_accuracy: 0.9737 - val_loss: 0.1376\n",
      "Epoch 52/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.9561 - val_loss: 0.1520\n",
      "Epoch 53/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9649 - val_loss: 0.1507\n",
      "Epoch 54/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0090 - val_accuracy: 0.9649 - val_loss: 0.1580\n",
      "Epoch 55/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9737 - val_loss: 0.1219\n",
      "Epoch 56/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0097 - val_accuracy: 0.9825 - val_loss: 0.1199\n",
      "Epoch 57/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9825 - val_loss: 0.0970\n",
      "Epoch 58/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0241 - val_accuracy: 0.9825 - val_loss: 0.1325\n",
      "Epoch 59/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0140 - val_accuracy: 0.9825 - val_loss: 0.1232\n",
      "Epoch 60/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0285 - val_accuracy: 0.9825 - val_loss: 0.1020\n",
      "Epoch 61/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.0074 - val_accuracy: 0.9474 - val_loss: 0.2592\n",
      "Epoch 62/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.9825 - val_loss: 0.1283\n",
      "Epoch 63/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9825 - val_loss: 0.1432\n",
      "Epoch 64/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9825 - val_loss: 0.1510\n",
      "Epoch 65/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0021 - val_accuracy: 0.9737 - val_loss: 0.1715\n",
      "Epoch 66/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9561 - val_loss: 0.2038\n",
      "Epoch 67/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0060 - val_accuracy: 0.9825 - val_loss: 0.1449\n",
      "Epoch 68/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0028 - val_accuracy: 0.9825 - val_loss: 0.1289\n",
      "Epoch 69/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0028 - val_accuracy: 0.9737 - val_loss: 0.1612\n",
      "Epoch 70/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9737 - val_loss: 0.1818\n",
      "Epoch 71/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9737 - val_loss: 0.1811\n",
      "Epoch 72/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0109 - val_accuracy: 0.9825 - val_loss: 0.2451\n",
      "Epoch 73/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0103 - val_accuracy: 0.9825 - val_loss: 0.1811\n",
      "Epoch 74/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0039 - val_accuracy: 0.9737 - val_loss: 0.2178\n",
      "Epoch 75/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.9825 - val_loss: 0.2036\n",
      "Epoch 76/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0317 - val_accuracy: 0.9474 - val_loss: 0.2825\n",
      "Epoch 77/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0143 - val_accuracy: 0.9825 - val_loss: 0.1992\n",
      "Epoch 78/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9825 - val_loss: 0.1769\n",
      "Epoch 79/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0232 - val_accuracy: 0.9825 - val_loss: 0.2485\n",
      "Epoch 80/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0040 - val_accuracy: 0.9737 - val_loss: 0.2515\n",
      "Epoch 81/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9474 - val_loss: 0.3111\n",
      "Epoch 82/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0212 - val_accuracy: 0.9825 - val_loss: 0.2054\n",
      "Epoch 83/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9561 - val_loss: 0.2570\n",
      "Epoch 84/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0068 - val_accuracy: 0.9737 - val_loss: 0.2060\n",
      "Epoch 85/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4655e-04 - val_accuracy: 0.9737 - val_loss: 0.1872\n",
      "Epoch 86/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4335e-04 - val_accuracy: 0.9737 - val_loss: 0.1883\n",
      "Epoch 87/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0026 - val_accuracy: 0.9825 - val_loss: 0.2174\n",
      "Epoch 88/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0064 - val_accuracy: 0.9825 - val_loss: 0.1946\n",
      "Epoch 89/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0038 - val_accuracy: 0.9825 - val_loss: 0.2062\n",
      "Epoch 90/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6333e-04 - val_accuracy: 0.9737 - val_loss: 0.1833\n",
      "Epoch 91/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0179 - val_accuracy: 0.9737 - val_loss: 0.2141\n",
      "Epoch 92/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9825 - val_loss: 0.2026\n",
      "Epoch 93/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9649 - val_loss: 0.2392\n",
      "Epoch 94/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9474 - val_loss: 0.2806\n",
      "Epoch 95/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9737 - val_loss: 0.2516\n",
      "Epoch 96/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9825 - val_loss: 0.2252\n",
      "Epoch 97/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9236e-04 - val_accuracy: 0.9825 - val_loss: 0.2201\n",
      "Epoch 98/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0167 - val_accuracy: 0.9825 - val_loss: 0.1745\n",
      "Epoch 99/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0200e-04 - val_accuracy: 0.9825 - val_loss: 0.1840\n",
      "Epoch 100/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0220 - val_accuracy: 0.9737 - val_loss: 0.2412\n",
      "Epoch 101/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0032 - val_accuracy: 0.9737 - val_loss: 0.1885\n",
      "Epoch 102/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.9737 - val_loss: 0.1984\n",
      "Epoch 103/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1302e-04 - val_accuracy: 0.9737 - val_loss: 0.1957\n",
      "Epoch 104/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9737 - val_loss: 0.1701\n",
      "Epoch 105/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.8256e-04 - val_accuracy: 0.9825 - val_loss: 0.1624\n",
      "Epoch 106/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.6947e-04 - val_accuracy: 0.9737 - val_loss: 0.1694\n",
      "Epoch 107/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6230e-04 - val_accuracy: 0.9737 - val_loss: 0.1895\n",
      "Epoch 108/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5595e-04 - val_accuracy: 0.9561 - val_loss: 0.2106\n",
      "Epoch 109/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.6820e-04 - val_accuracy: 0.9737 - val_loss: 0.1888\n",
      "Epoch 110/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0035 - val_accuracy: 0.9825 - val_loss: 0.1489\n",
      "Epoch 111/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9737 - val_loss: 0.1764\n",
      "Epoch 112/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9825 - val_loss: 0.1572\n",
      "Epoch 113/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.6337e-05 - val_accuracy: 0.9825 - val_loss: 0.1531\n",
      "Epoch 114/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6456e-04 - val_accuracy: 0.9825 - val_loss: 0.1535\n",
      "Epoch 115/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4005e-04 - val_accuracy: 0.9825 - val_loss: 0.1610\n",
      "Epoch 116/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9825 - val_loss: 0.1852\n",
      "Epoch 117/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9437e-04 - val_accuracy: 0.9649 - val_loss: 0.2131\n",
      "Epoch 118/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.7763e-04 - val_accuracy: 0.9649 - val_loss: 0.2194\n",
      "Epoch 119/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5223e-04 - val_accuracy: 0.9649 - val_loss: 0.2159\n",
      "Epoch 120/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9825 - val_loss: 0.1608\n",
      "Epoch 121/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0146 - val_accuracy: 0.9211 - val_loss: 0.3263\n",
      "Epoch 122/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0040 - val_accuracy: 0.9737 - val_loss: 0.1453\n",
      "Epoch 123/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0075 - val_accuracy: 0.9649 - val_loss: 0.2108\n",
      "Epoch 124/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.9795e-04 - val_accuracy: 0.9649 - val_loss: 0.2292\n",
      "Epoch 125/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9649 - val_loss: 0.1961\n",
      "Epoch 126/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7316e-04 - val_accuracy: 0.9825 - val_loss: 0.1420\n",
      "Epoch 127/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0055 - val_accuracy: 0.9737 - val_loss: 0.2161\n",
      "Epoch 128/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7012e-04 - val_accuracy: 0.9561 - val_loss: 0.2370\n",
      "Epoch 129/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5385e-04 - val_accuracy: 0.9561 - val_loss: 0.2531\n",
      "Epoch 130/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0820e-04 - val_accuracy: 0.9737 - val_loss: 0.2379\n",
      "Epoch 131/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.9235e-04 - val_accuracy: 0.9737 - val_loss: 0.2324\n",
      "Epoch 132/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2710e-05 - val_accuracy: 0.9737 - val_loss: 0.2311\n",
      "Epoch 133/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9649 - val_loss: 0.2471\n",
      "Epoch 134/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8788e-04 - val_accuracy: 0.9649 - val_loss: 0.2503\n",
      "Epoch 135/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1422e-04 - val_accuracy: 0.9649 - val_loss: 0.2586\n",
      "Epoch 136/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8545e-04 - val_accuracy: 0.9649 - val_loss: 0.2543\n",
      "Epoch 137/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2058e-04 - val_accuracy: 0.9649 - val_loss: 0.2517\n",
      "Epoch 138/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9776e-04 - val_accuracy: 0.9649 - val_loss: 0.2532\n",
      "Epoch 139/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0062e-04 - val_accuracy: 0.9737 - val_loss: 0.2475\n",
      "Epoch 140/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4838e-05 - val_accuracy: 0.9737 - val_loss: 0.2434\n",
      "Epoch 141/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9158e-04 - val_accuracy: 0.9737 - val_loss: 0.2468\n",
      "Epoch 142/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9561 - val_loss: 0.3365\n",
      "Epoch 143/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6426e-04 - val_accuracy: 0.9474 - val_loss: 0.4356\n",
      "Epoch 144/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 0.9649 - val_loss: 0.2599\n",
      "Epoch 145/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9649 - val_loss: 0.2739\n",
      "Epoch 146/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.7253e-04 - val_accuracy: 0.9561 - val_loss: 0.2931\n",
      "Epoch 147/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9298 - val_loss: 0.4269\n",
      "Epoch 148/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0023 - val_accuracy: 0.9737 - val_loss: 0.2421\n",
      "Epoch 149/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0030 - val_accuracy: 0.9737 - val_loss: 0.2558\n",
      "Epoch 150/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0056 - val_accuracy: 0.9211 - val_loss: 0.4500\n",
      "Epoch 151/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0071 - val_accuracy: 0.9737 - val_loss: 0.2288\n",
      "Epoch 152/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0125 - val_accuracy: 0.9737 - val_loss: 0.2713\n",
      "Epoch 153/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9737 - val_loss: 0.2414\n",
      "Epoch 154/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8981e-04 - val_accuracy: 0.9737 - val_loss: 0.2554\n",
      "Epoch 155/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9737 - val_loss: 0.2498\n",
      "Epoch 156/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9737 - val_loss: 0.2370\n",
      "Epoch 157/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9683e-04 - val_accuracy: 0.9737 - val_loss: 0.2434\n",
      "Epoch 158/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8949e-04 - val_accuracy: 0.9737 - val_loss: 0.2445\n",
      "Epoch 159/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0917e-04 - val_accuracy: 0.9737 - val_loss: 0.2117\n",
      "Epoch 160/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2588e-04 - val_accuracy: 0.9737 - val_loss: 0.2054\n",
      "Epoch 161/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9812e-04 - val_accuracy: 0.9737 - val_loss: 0.2085\n",
      "Epoch 162/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1312e-04 - val_accuracy: 0.9737 - val_loss: 0.2421\n",
      "Epoch 163/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9737 - val_loss: 0.2565\n",
      "Epoch 164/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0015 - val_accuracy: 0.9649 - val_loss: 0.2859\n",
      "Epoch 165/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3128e-04 - val_accuracy: 0.9649 - val_loss: 0.2523\n",
      "Epoch 166/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1943e-04 - val_accuracy: 0.9649 - val_loss: 0.2574\n",
      "Epoch 167/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2796e-05 - val_accuracy: 0.9649 - val_loss: 0.2576\n",
      "Epoch 168/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8381e-05 - val_accuracy: 0.9649 - val_loss: 0.2581\n",
      "Epoch 169/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3918e-04 - val_accuracy: 0.9649 - val_loss: 0.2576\n",
      "Epoch 170/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1700e-04 - val_accuracy: 0.9649 - val_loss: 0.2633\n",
      "Epoch 171/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.4750e-05 - val_accuracy: 0.9649 - val_loss: 0.2671\n",
      "Epoch 172/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0358e-04 - val_accuracy: 0.9649 - val_loss: 0.2631\n",
      "Epoch 173/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8630e-05 - val_accuracy: 0.9649 - val_loss: 0.2485\n",
      "Epoch 174/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9561 - val_loss: 0.3204\n",
      "Epoch 175/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9649 - val_loss: 0.2978\n",
      "Epoch 176/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.6252e-04 - val_accuracy: 0.9737 - val_loss: 0.2787\n",
      "Epoch 177/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6275e-04 - val_accuracy: 0.9737 - val_loss: 0.2947\n",
      "Epoch 178/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0021 - val_accuracy: 0.9386 - val_loss: 0.4423\n",
      "Epoch 179/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9474 - val_loss: 0.4487\n",
      "Epoch 180/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9737 - val_loss: 0.2454\n",
      "Epoch 181/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8053e-04 - val_accuracy: 0.9737 - val_loss: 0.2670\n",
      "Epoch 182/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6069e-04 - val_accuracy: 0.9737 - val_loss: 0.2678\n",
      "Epoch 183/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5033e-05 - val_accuracy: 0.9737 - val_loss: 0.2418\n",
      "Epoch 184/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4688e-05 - val_accuracy: 0.9825 - val_loss: 0.2410\n",
      "Epoch 185/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.2953e-04 - val_accuracy: 0.9825 - val_loss: 0.2264\n",
      "Epoch 186/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8538e-04 - val_accuracy: 0.9825 - val_loss: 0.2223\n",
      "Epoch 187/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0060 - val_accuracy: 0.9737 - val_loss: 0.2650\n",
      "Epoch 188/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7835e-05 - val_accuracy: 0.9737 - val_loss: 0.2713\n",
      "Epoch 189/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7574e-04 - val_accuracy: 0.9737 - val_loss: 0.2850\n",
      "Epoch 190/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3495e-04 - val_accuracy: 0.9737 - val_loss: 0.2782\n",
      "Epoch 191/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6785e-05 - val_accuracy: 0.9737 - val_loss: 0.2712\n",
      "Epoch 192/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6147e-05 - val_accuracy: 0.9737 - val_loss: 0.2712\n",
      "Epoch 193/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.3201e-04 - val_accuracy: 0.9737 - val_loss: 0.3163\n",
      "Epoch 194/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5587e-05 - val_accuracy: 0.9737 - val_loss: 0.3273\n",
      "Epoch 195/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0335e-05 - val_accuracy: 0.9737 - val_loss: 0.3276\n",
      "Epoch 196/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5396e-04 - val_accuracy: 0.9737 - val_loss: 0.3190\n",
      "Epoch 197/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9737 - val_loss: 0.3329\n",
      "Epoch 198/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9737 - val_loss: 0.2865\n",
      "Epoch 199/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.9193e-05 - val_accuracy: 0.9737 - val_loss: 0.2831\n",
      "Epoch 200/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4619e-04 - val_accuracy: 0.9737 - val_loss: 0.3061\n",
      "Epoch 201/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1450e-05 - val_accuracy: 0.9649 - val_loss: 0.3181\n",
      "Epoch 202/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.2148e-05 - val_accuracy: 0.9649 - val_loss: 0.3167\n",
      "Epoch 203/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2246e-04 - val_accuracy: 0.9649 - val_loss: 0.3215\n",
      "Epoch 204/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0825e-04 - val_accuracy: 0.9649 - val_loss: 0.3224\n",
      "Epoch 205/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9025e-05 - val_accuracy: 0.9649 - val_loss: 0.3241\n",
      "Epoch 206/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.5087e-05 - val_accuracy: 0.9649 - val_loss: 0.3237\n",
      "Epoch 207/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2130e-05 - val_accuracy: 0.9649 - val_loss: 0.3235\n",
      "Epoch 208/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9072e-05 - val_accuracy: 0.9649 - val_loss: 0.3229\n",
      "Epoch 209/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3163e-05 - val_accuracy: 0.9649 - val_loss: 0.3221\n",
      "Epoch 210/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0076e-06 - val_accuracy: 0.9649 - val_loss: 0.3230\n",
      "Epoch 211/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.1091e-06 - val_accuracy: 0.9649 - val_loss: 0.3229\n",
      "Epoch 212/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5951e-05 - val_accuracy: 0.9649 - val_loss: 0.3233\n",
      "Epoch 213/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3317e-05 - val_accuracy: 0.9649 - val_loss: 0.3295\n",
      "Epoch 214/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1410e-04 - val_accuracy: 0.9737 - val_loss: 0.3867\n",
      "Epoch 215/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0171 - val_accuracy: 0.9737 - val_loss: 0.2420\n",
      "Epoch 216/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2594e-05 - val_accuracy: 0.9825 - val_loss: 0.2095\n",
      "Epoch 217/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4430e-04 - val_accuracy: 0.9825 - val_loss: 0.2231\n",
      "Epoch 218/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7114e-04 - val_accuracy: 0.9825 - val_loss: 0.2338\n",
      "Epoch 219/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.3033e-05 - val_accuracy: 0.9825 - val_loss: 0.2350\n",
      "Epoch 220/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3895e-04 - val_accuracy: 0.9825 - val_loss: 0.2439\n",
      "Epoch 221/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1564e-04 - val_accuracy: 0.9737 - val_loss: 0.2621\n",
      "Epoch 222/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4187e-04 - val_accuracy: 0.9737 - val_loss: 0.2656\n",
      "Epoch 223/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4216e-04 - val_accuracy: 0.9737 - val_loss: 0.2705\n",
      "Epoch 224/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4818e-04 - val_accuracy: 0.9737 - val_loss: 0.2805\n",
      "Epoch 225/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3007e-04 - val_accuracy: 0.9649 - val_loss: 0.2924\n",
      "Epoch 226/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7468e-05 - val_accuracy: 0.9649 - val_loss: 0.3021\n",
      "Epoch 227/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2014e-05 - val_accuracy: 0.9649 - val_loss: 0.3019\n",
      "Epoch 228/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9825 - val_loss: 0.2623\n",
      "Epoch 229/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9825 - val_loss: 0.2341\n",
      "Epoch 230/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0050 - val_accuracy: 0.9649 - val_loss: 0.3317\n",
      "Epoch 231/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0033 - val_accuracy: 0.9561 - val_loss: 0.4666\n",
      "Epoch 232/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8176e-04 - val_accuracy: 0.9649 - val_loss: 0.2771\n",
      "Epoch 233/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0046 - val_accuracy: 0.9737 - val_loss: 0.2734\n",
      "Epoch 234/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0099 - val_accuracy: 0.9649 - val_loss: 0.2719\n",
      "Epoch 235/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0042 - val_accuracy: 0.9561 - val_loss: 0.3994\n",
      "Epoch 236/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9474 - val_loss: 0.3817\n",
      "Epoch 237/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0020 - val_accuracy: 0.9737 - val_loss: 0.2634\n",
      "Epoch 238/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.2113e-04 - val_accuracy: 0.9737 - val_loss: 0.2607\n",
      "Epoch 239/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1314e-04 - val_accuracy: 0.9649 - val_loss: 0.2977\n",
      "Epoch 240/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2572e-04 - val_accuracy: 0.9649 - val_loss: 0.2848\n",
      "Epoch 241/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2366e-04 - val_accuracy: 0.9649 - val_loss: 0.2777\n",
      "Epoch 242/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4620e-04 - val_accuracy: 0.9737 - val_loss: 0.2635\n",
      "Epoch 243/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0296e-04 - val_accuracy: 0.9737 - val_loss: 0.2633\n",
      "Epoch 244/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9561 - val_loss: 0.3283\n",
      "Epoch 245/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2098e-04 - val_accuracy: 0.9561 - val_loss: 0.3285\n",
      "Epoch 246/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9032e-05 - val_accuracy: 0.9649 - val_loss: 0.3003\n",
      "Epoch 247/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.7580e-05 - val_accuracy: 0.9649 - val_loss: 0.2978\n",
      "Epoch 248/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9880e-04 - val_accuracy: 0.9649 - val_loss: 0.2850\n",
      "Epoch 249/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6270e-05 - val_accuracy: 0.9649 - val_loss: 0.2806\n",
      "Epoch 250/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5422e-05 - val_accuracy: 0.9649 - val_loss: 0.2756\n",
      "Epoch 251/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3210e-05 - val_accuracy: 0.9649 - val_loss: 0.2743\n",
      "Epoch 252/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6444e-05 - val_accuracy: 0.9649 - val_loss: 0.2734\n",
      "Epoch 253/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9585e-05 - val_accuracy: 0.9649 - val_loss: 0.2748\n",
      "Epoch 254/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1189e-04 - val_accuracy: 0.9649 - val_loss: 0.2884\n",
      "Epoch 255/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3019e-05 - val_accuracy: 0.9649 - val_loss: 0.2899\n",
      "Epoch 256/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.7112e-05 - val_accuracy: 0.9649 - val_loss: 0.2784\n",
      "Epoch 257/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1961e-04 - val_accuracy: 0.9737 - val_loss: 0.2627\n",
      "Epoch 258/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7704e-04 - val_accuracy: 0.9649 - val_loss: 0.3043\n",
      "Epoch 259/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9516e-05 - val_accuracy: 0.9561 - val_loss: 0.3939\n",
      "Epoch 260/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0830e-04 - val_accuracy: 0.9649 - val_loss: 0.2995\n",
      "Epoch 261/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1754e-05 - val_accuracy: 0.9737 - val_loss: 0.2421\n",
      "Epoch 262/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5343e-04 - val_accuracy: 0.9737 - val_loss: 0.2513\n",
      "Epoch 263/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.5448e-04 - val_accuracy: 0.9649 - val_loss: 0.2896\n",
      "Epoch 264/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3341e-04 - val_accuracy: 0.9649 - val_loss: 0.2865\n",
      "Epoch 265/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9793e-05 - val_accuracy: 0.9649 - val_loss: 0.2854\n",
      "Epoch 266/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.2360e-04 - val_accuracy: 0.9737 - val_loss: 0.3357\n",
      "Epoch 267/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4546e-05 - val_accuracy: 0.9737 - val_loss: 0.3384\n",
      "Epoch 268/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2821e-04 - val_accuracy: 0.9737 - val_loss: 0.2716\n",
      "Epoch 269/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2337e-05 - val_accuracy: 0.9737 - val_loss: 0.2584\n",
      "Epoch 270/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9936e-06 - val_accuracy: 0.9737 - val_loss: 0.2573\n",
      "Epoch 271/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7816e-04 - val_accuracy: 0.9737 - val_loss: 0.2930\n",
      "Epoch 272/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3533e-04 - val_accuracy: 0.9737 - val_loss: 0.2868\n",
      "Epoch 273/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3772e-05 - val_accuracy: 0.9737 - val_loss: 0.2809\n",
      "Epoch 274/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9284e-05 - val_accuracy: 0.9737 - val_loss: 0.2816\n",
      "Epoch 275/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2841e-05 - val_accuracy: 0.9737 - val_loss: 0.2820\n",
      "Epoch 276/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3331e-04 - val_accuracy: 0.9737 - val_loss: 0.2870\n",
      "Epoch 277/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6729e-05 - val_accuracy: 0.9737 - val_loss: 0.2925\n",
      "Epoch 278/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.7209e-06 - val_accuracy: 0.9737 - val_loss: 0.2970\n",
      "Epoch 279/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9825 - val_loss: 0.2666\n",
      "Epoch 280/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2548e-04 - val_accuracy: 0.9737 - val_loss: 0.2975\n",
      "Epoch 281/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8788e-06 - val_accuracy: 0.9649 - val_loss: 0.3121\n",
      "Epoch 282/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0421e-05 - val_accuracy: 0.9649 - val_loss: 0.3152\n",
      "Epoch 283/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4274e-04 - val_accuracy: 0.9649 - val_loss: 0.3170\n",
      "Epoch 284/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8831e-06 - val_accuracy: 0.9649 - val_loss: 0.3172\n",
      "Epoch 285/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8923e-05 - val_accuracy: 0.9649 - val_loss: 0.3150\n",
      "Epoch 286/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2487e-05 - val_accuracy: 0.9649 - val_loss: 0.3168\n",
      "Epoch 287/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3593e-05 - val_accuracy: 0.9649 - val_loss: 0.3170\n",
      "Epoch 288/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.9699e-05 - val_accuracy: 0.9649 - val_loss: 0.3147\n",
      "Epoch 289/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3181e-06 - val_accuracy: 0.9649 - val_loss: 0.2980\n",
      "Epoch 290/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0138e-05 - val_accuracy: 0.9649 - val_loss: 0.2951\n",
      "Epoch 291/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6669e-06 - val_accuracy: 0.9737 - val_loss: 0.2945\n",
      "Epoch 292/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8059e-05 - val_accuracy: 0.9737 - val_loss: 0.2933\n",
      "Epoch 293/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2489e-05 - val_accuracy: 0.9649 - val_loss: 0.2959\n",
      "Epoch 294/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0810e-05 - val_accuracy: 0.9649 - val_loss: 0.2960\n",
      "Epoch 295/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3037e-05 - val_accuracy: 0.9649 - val_loss: 0.3027\n",
      "Epoch 296/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4797e-06 - val_accuracy: 0.9649 - val_loss: 0.3026\n",
      "Epoch 297/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3204e-05 - val_accuracy: 0.9649 - val_loss: 0.3025\n",
      "Epoch 298/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.7026e-06 - val_accuracy: 0.9649 - val_loss: 0.3022\n",
      "Epoch 299/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4281e-06 - val_accuracy: 0.9649 - val_loss: 0.3024\n",
      "Epoch 300/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1227e-06 - val_accuracy: 0.9649 - val_loss: 0.3027\n",
      "Epoch 301/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8165e-07 - val_accuracy: 0.9649 - val_loss: 0.3029\n",
      "Epoch 302/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5319e-04 - val_accuracy: 0.9474 - val_loss: 0.4996\n",
      "Epoch 303/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5024e-05 - val_accuracy: 0.9386 - val_loss: 0.6076\n",
      "Epoch 304/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3913e-05 - val_accuracy: 0.9386 - val_loss: 0.6083\n",
      "Epoch 305/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0954e-04 - val_accuracy: 0.9386 - val_loss: 0.6010\n",
      "Epoch 306/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.2435e-04 - val_accuracy: 0.9561 - val_loss: 0.4723\n",
      "Epoch 307/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0626e-05 - val_accuracy: 0.9561 - val_loss: 0.3502\n",
      "Epoch 308/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9851e-05 - val_accuracy: 0.9561 - val_loss: 0.3444\n",
      "Epoch 309/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0112 - val_accuracy: 0.9474 - val_loss: 0.5764\n",
      "Epoch 310/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5843e-05 - val_accuracy: 0.9474 - val_loss: 0.5340\n",
      "Epoch 311/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3068e-04 - val_accuracy: 0.9474 - val_loss: 0.5993\n",
      "Epoch 312/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.4141e-05 - val_accuracy: 0.9386 - val_loss: 0.6614\n",
      "Epoch 313/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3200e-04 - val_accuracy: 0.9386 - val_loss: 0.6279\n",
      "Epoch 314/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4247e-05 - val_accuracy: 0.9474 - val_loss: 0.6157\n",
      "Epoch 315/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.0159e-06 - val_accuracy: 0.9474 - val_loss: 0.6128\n",
      "Epoch 316/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8367e-05 - val_accuracy: 0.9474 - val_loss: 0.5760\n",
      "Epoch 317/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6014e-05 - val_accuracy: 0.9474 - val_loss: 0.5513\n",
      "Epoch 318/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9670e-04 - val_accuracy: 0.9298 - val_loss: 0.6158\n",
      "Epoch 319/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0086 - val_accuracy: 0.9737 - val_loss: 0.3948\n",
      "Epoch 320/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0225 - val_accuracy: 0.9561 - val_loss: 0.4436\n",
      "Epoch 321/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4317e-04 - val_accuracy: 0.9561 - val_loss: 0.4740\n",
      "Epoch 322/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0217e-05 - val_accuracy: 0.9561 - val_loss: 0.4621\n",
      "Epoch 323/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0874e-04 - val_accuracy: 0.9649 - val_loss: 0.4519\n",
      "Epoch 324/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.1261 - val_accuracy: 0.9649 - val_loss: 0.4647\n",
      "Epoch 325/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0022 - val_accuracy: 0.9737 - val_loss: 0.2966\n",
      "Epoch 326/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0081 - val_accuracy: 0.9649 - val_loss: 0.3653\n",
      "Epoch 327/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9561 - val_loss: 0.4849\n",
      "Epoch 328/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0093 - val_accuracy: 0.9561 - val_loss: 0.4024\n",
      "Epoch 329/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5572e-05 - val_accuracy: 0.9561 - val_loss: 0.3325\n",
      "Epoch 330/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0082 - val_accuracy: 0.9474 - val_loss: 0.5743\n",
      "Epoch 331/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0066 - val_accuracy: 0.9474 - val_loss: 0.3409\n",
      "Epoch 332/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0021 - val_accuracy: 0.9474 - val_loss: 0.3955\n",
      "Epoch 333/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9922e-04 - val_accuracy: 0.9737 - val_loss: 0.2915\n",
      "Epoch 334/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7438e-04 - val_accuracy: 0.9737 - val_loss: 0.2737\n",
      "Epoch 335/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0210 - val_accuracy: 0.9737 - val_loss: 0.4580\n",
      "Epoch 336/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0230 - val_accuracy: 0.9649 - val_loss: 0.3919\n",
      "Epoch 337/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0061 - val_accuracy: 0.9649 - val_loss: 0.3185\n",
      "Epoch 338/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0369 - val_accuracy: 0.9561 - val_loss: 0.4396\n",
      "Epoch 339/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9649 - val_loss: 0.3565\n",
      "Epoch 340/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9135e-04 - val_accuracy: 0.9737 - val_loss: 0.3299\n",
      "Epoch 341/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8396e-04 - val_accuracy: 0.9737 - val_loss: 0.3315\n",
      "Epoch 342/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1563e-05 - val_accuracy: 0.9737 - val_loss: 0.3351\n",
      "Epoch 343/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9737 - val_loss: 0.3397\n",
      "Epoch 344/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4237e-04 - val_accuracy: 0.9737 - val_loss: 0.3268\n",
      "Epoch 345/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.6667e-04 - val_accuracy: 0.9737 - val_loss: 0.3352\n",
      "Epoch 346/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1137e-05 - val_accuracy: 0.9737 - val_loss: 0.3397\n",
      "Epoch 347/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4029e-04 - val_accuracy: 0.9737 - val_loss: 0.3417\n",
      "Epoch 348/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0790e-04 - val_accuracy: 0.9737 - val_loss: 0.3442\n",
      "Epoch 349/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2580e-04 - val_accuracy: 0.9737 - val_loss: 0.3440\n",
      "Epoch 350/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.3617e-05 - val_accuracy: 0.9737 - val_loss: 0.3438\n",
      "Epoch 351/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 4.7751e-04 - val_accuracy: 0.9737 - val_loss: 0.3527\n",
      "Epoch 352/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9561 - val_loss: 0.4486\n",
      "Epoch 353/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0643e-04 - val_accuracy: 0.9649 - val_loss: 0.3632\n",
      "Epoch 354/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.9649 - val_loss: 0.3857\n",
      "Epoch 355/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0013 - val_accuracy: 0.9737 - val_loss: 0.3178\n",
      "Epoch 356/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0122e-04 - val_accuracy: 0.9737 - val_loss: 0.3052\n",
      "Epoch 357/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0077 - val_accuracy: 0.9649 - val_loss: 0.4070\n",
      "Epoch 358/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.9141e-05 - val_accuracy: 0.9561 - val_loss: 0.4418\n",
      "Epoch 359/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.7530e-04 - val_accuracy: 0.9561 - val_loss: 0.4392\n",
      "Epoch 360/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7197e-04 - val_accuracy: 0.9561 - val_loss: 0.4201\n",
      "Epoch 361/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9649 - val_loss: 0.3929\n",
      "Epoch 362/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7438e-05 - val_accuracy: 0.9649 - val_loss: 0.3779\n",
      "Epoch 363/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.6824e-05 - val_accuracy: 0.9649 - val_loss: 0.3742\n",
      "Epoch 364/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9737 - val_loss: 0.2949\n",
      "Epoch 365/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2257e-04 - val_accuracy: 0.9737 - val_loss: 0.2422\n",
      "Epoch 366/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8915e-04 - val_accuracy: 0.9737 - val_loss: 0.2565\n",
      "Epoch 367/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0464 - val_accuracy: 0.9561 - val_loss: 0.5845\n",
      "Epoch 368/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9561 - val_loss: 0.5334\n",
      "Epoch 369/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0048 - val_accuracy: 0.9737 - val_loss: 0.4320\n",
      "Epoch 370/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 0.9649 - val_loss: 0.4528\n",
      "Epoch 371/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6794e-04 - val_accuracy: 0.9561 - val_loss: 0.4511\n",
      "Epoch 372/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6294e-04 - val_accuracy: 0.9561 - val_loss: 0.4608\n",
      "Epoch 373/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1525e-04 - val_accuracy: 0.9561 - val_loss: 0.4654\n",
      "Epoch 374/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7128e-05 - val_accuracy: 0.9561 - val_loss: 0.4668\n",
      "Epoch 375/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5958e-04 - val_accuracy: 0.9561 - val_loss: 0.4656\n",
      "Epoch 376/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5689e-04 - val_accuracy: 0.9561 - val_loss: 0.4588\n",
      "Epoch 377/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4415e-04 - val_accuracy: 0.9561 - val_loss: 0.4527\n",
      "Epoch 378/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4717e-04 - val_accuracy: 0.9561 - val_loss: 0.4488\n",
      "Epoch 379/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8513e-05 - val_accuracy: 0.9561 - val_loss: 0.4460\n",
      "Epoch 380/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9268e-04 - val_accuracy: 0.9561 - val_loss: 0.4505\n",
      "Epoch 381/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0178e-05 - val_accuracy: 0.9561 - val_loss: 0.4493\n",
      "Epoch 382/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.0806e-05 - val_accuracy: 0.9561 - val_loss: 0.4523\n",
      "Epoch 383/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2079e-04 - val_accuracy: 0.9561 - val_loss: 0.4652\n",
      "Epoch 384/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2189e-05 - val_accuracy: 0.9561 - val_loss: 0.4666\n",
      "Epoch 385/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1462e-04 - val_accuracy: 0.9561 - val_loss: 0.4628\n",
      "Epoch 386/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0642e-04 - val_accuracy: 0.9561 - val_loss: 0.5102\n",
      "Epoch 387/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3172e-04 - val_accuracy: 0.9561 - val_loss: 0.5261\n",
      "Epoch 388/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4571e-05 - val_accuracy: 0.9561 - val_loss: 0.5244\n",
      "Epoch 389/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7824e-05 - val_accuracy: 0.9561 - val_loss: 0.5152\n",
      "Epoch 390/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.8200e-05 - val_accuracy: 0.9561 - val_loss: 0.5111\n",
      "Epoch 391/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2676e-05 - val_accuracy: 0.9561 - val_loss: 0.5098\n",
      "Epoch 392/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.5676e-05 - val_accuracy: 0.9561 - val_loss: 0.5100\n",
      "Epoch 393/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9297e-06 - val_accuracy: 0.9561 - val_loss: 0.5096\n",
      "Epoch 394/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4253e-04 - val_accuracy: 0.9561 - val_loss: 0.4927\n",
      "Epoch 395/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8115e-05 - val_accuracy: 0.9561 - val_loss: 0.4880\n",
      "Epoch 396/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3057e-05 - val_accuracy: 0.9561 - val_loss: 0.4879\n",
      "Epoch 397/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4916e-05 - val_accuracy: 0.9561 - val_loss: 0.4806\n",
      "Epoch 398/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3317e-05 - val_accuracy: 0.9561 - val_loss: 0.4794\n",
      "Epoch 399/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0296e-04 - val_accuracy: 0.9561 - val_loss: 0.4848\n",
      "Epoch 400/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4119e-05 - val_accuracy: 0.9561 - val_loss: 0.4874\n",
      "Epoch 401/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.1169e-04 - val_accuracy: 0.9561 - val_loss: 0.4780\n",
      "Epoch 402/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3487e-05 - val_accuracy: 0.9561 - val_loss: 0.4759\n",
      "Epoch 403/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.3998e-05 - val_accuracy: 0.9561 - val_loss: 0.4759\n",
      "Epoch 404/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0087e-05 - val_accuracy: 0.9561 - val_loss: 0.4776\n",
      "Epoch 405/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0817e-04 - val_accuracy: 0.9561 - val_loss: 0.4857\n",
      "Epoch 406/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6772e-04 - val_accuracy: 0.9561 - val_loss: 0.4841\n",
      "Epoch 407/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2159e-05 - val_accuracy: 0.9561 - val_loss: 0.4828\n",
      "Epoch 408/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3152e-06 - val_accuracy: 0.9561 - val_loss: 0.4823\n",
      "Epoch 409/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3059e-04 - val_accuracy: 0.9649 - val_loss: 0.4734\n",
      "Epoch 410/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9528e-05 - val_accuracy: 0.9649 - val_loss: 0.4707\n",
      "Epoch 411/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6476e-05 - val_accuracy: 0.9649 - val_loss: 0.4697\n",
      "Epoch 412/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2663e-06 - val_accuracy: 0.9649 - val_loss: 0.4697\n",
      "Epoch 413/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0804e-05 - val_accuracy: 0.9649 - val_loss: 0.4698\n",
      "Epoch 414/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 0.9211 - val_loss: 0.8783\n",
      "Epoch 415/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0466 - val_accuracy: 0.9649 - val_loss: 0.4932\n",
      "Epoch 416/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2690e-04 - val_accuracy: 0.9649 - val_loss: 0.4603\n",
      "Epoch 417/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6264e-04 - val_accuracy: 0.9649 - val_loss: 0.4532\n",
      "Epoch 418/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0041 - val_accuracy: 0.9737 - val_loss: 0.3634\n",
      "Epoch 419/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0148 - val_accuracy: 0.9737 - val_loss: 0.4059\n",
      "Epoch 420/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.5599e-04 - val_accuracy: 0.9737 - val_loss: 0.3871\n",
      "Epoch 421/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6293e-04 - val_accuracy: 0.9737 - val_loss: 0.3786\n",
      "Epoch 422/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4331e-04 - val_accuracy: 0.9737 - val_loss: 0.3745\n",
      "Epoch 423/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0232e-04 - val_accuracy: 0.9737 - val_loss: 0.3713\n",
      "Epoch 424/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3309e-05 - val_accuracy: 0.9737 - val_loss: 0.3529\n",
      "Epoch 425/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8135e-04 - val_accuracy: 0.9737 - val_loss: 0.3667\n",
      "Epoch 426/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2990e-05 - val_accuracy: 0.9649 - val_loss: 0.3771\n",
      "Epoch 427/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.9568e-04 - val_accuracy: 0.9474 - val_loss: 0.4663\n",
      "Epoch 428/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.9737 - val_loss: 0.3499\n",
      "Epoch 429/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4478e-04 - val_accuracy: 0.9737 - val_loss: 0.3421\n",
      "Epoch 430/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7968e-04 - val_accuracy: 0.9737 - val_loss: 0.3460\n",
      "Epoch 431/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0138 - val_accuracy: 0.9649 - val_loss: 0.3933\n",
      "Epoch 432/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.9491e-04 - val_accuracy: 0.9649 - val_loss: 0.3903\n",
      "Epoch 433/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6639e-04 - val_accuracy: 0.9649 - val_loss: 0.4003\n",
      "Epoch 434/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0082 - val_accuracy: 0.9737 - val_loss: 0.2793\n",
      "Epoch 435/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1522e-04 - val_accuracy: 0.9737 - val_loss: 0.2888\n",
      "Epoch 436/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2864e-06 - val_accuracy: 0.9737 - val_loss: 0.2974\n",
      "Epoch 437/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8066e-04 - val_accuracy: 0.9737 - val_loss: 0.2973\n",
      "Epoch 438/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2362e-05 - val_accuracy: 0.9737 - val_loss: 0.2978\n",
      "Epoch 439/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.3409e-05 - val_accuracy: 0.9737 - val_loss: 0.3035\n",
      "Epoch 440/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.1422e-06 - val_accuracy: 0.9737 - val_loss: 0.3069\n",
      "Epoch 441/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6513e-05 - val_accuracy: 0.9737 - val_loss: 0.3070\n",
      "Epoch 442/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4092e-06 - val_accuracy: 0.9737 - val_loss: 0.3071\n",
      "Epoch 443/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0157e-05 - val_accuracy: 0.9737 - val_loss: 0.3071\n",
      "Epoch 444/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5775e-05 - val_accuracy: 0.9737 - val_loss: 0.3071\n",
      "Epoch 445/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0383e-06 - val_accuracy: 0.9737 - val_loss: 0.3075\n",
      "Epoch 446/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9442e-05 - val_accuracy: 0.9737 - val_loss: 0.3112\n",
      "Epoch 447/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3564e-04 - val_accuracy: 0.9737 - val_loss: 0.3068\n",
      "Epoch 448/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7642e-06 - val_accuracy: 0.9737 - val_loss: 0.3061\n",
      "Epoch 449/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1194e-05 - val_accuracy: 0.9737 - val_loss: 0.3066\n",
      "Epoch 450/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0920e-04 - val_accuracy: 0.9649 - val_loss: 0.3238\n",
      "Epoch 451/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2954e-04 - val_accuracy: 0.9649 - val_loss: 0.3545\n",
      "Epoch 452/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0014 - val_accuracy: 0.9474 - val_loss: 0.5263\n",
      "Epoch 453/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0049 - val_accuracy: 0.9649 - val_loss: 0.3922\n",
      "Epoch 454/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5544e-04 - val_accuracy: 0.9649 - val_loss: 0.3460\n",
      "Epoch 455/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7052e-04 - val_accuracy: 0.9649 - val_loss: 0.3436\n",
      "Epoch 456/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1776e-05 - val_accuracy: 0.9649 - val_loss: 0.3465\n",
      "Epoch 457/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3093e-05 - val_accuracy: 0.9649 - val_loss: 0.3533\n",
      "Epoch 458/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.7307e-05 - val_accuracy: 0.9649 - val_loss: 0.3547\n",
      "Epoch 459/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2396e-05 - val_accuracy: 0.9649 - val_loss: 0.3558\n",
      "Epoch 460/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8730e-05 - val_accuracy: 0.9649 - val_loss: 0.3614\n",
      "Epoch 461/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2812e-04 - val_accuracy: 0.9649 - val_loss: 0.3729\n",
      "Epoch 462/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8332e-05 - val_accuracy: 0.9649 - val_loss: 0.3798\n",
      "Epoch 463/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2327e-05 - val_accuracy: 0.9649 - val_loss: 0.3770\n",
      "Epoch 464/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.2442e-04 - val_accuracy: 0.9649 - val_loss: 0.4546\n",
      "Epoch 465/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.9649 - val_loss: 0.3747\n",
      "Epoch 466/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5457e-05 - val_accuracy: 0.9561 - val_loss: 0.4415\n",
      "Epoch 467/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 4.1327e-04 - val_accuracy: 0.9649 - val_loss: 0.3731\n",
      "Epoch 468/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9737 - val_loss: 0.3150\n",
      "Epoch 469/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6332e-04 - val_accuracy: 0.9561 - val_loss: 0.3793\n",
      "Epoch 470/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0081 - val_accuracy: 0.9737 - val_loss: 0.2855\n",
      "Epoch 471/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9737 - val_loss: 0.3067\n",
      "Epoch 472/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1688e-04 - val_accuracy: 0.9737 - val_loss: 0.3174\n",
      "Epoch 473/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6084e-05 - val_accuracy: 0.9737 - val_loss: 0.3190\n",
      "Epoch 474/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2568e-04 - val_accuracy: 0.9737 - val_loss: 0.3253\n",
      "Epoch 475/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6401e-04 - val_accuracy: 0.9737 - val_loss: 0.3289\n",
      "Epoch 476/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6842e-04 - val_accuracy: 0.9737 - val_loss: 0.3360\n",
      "Epoch 477/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5398e-04 - val_accuracy: 0.9737 - val_loss: 0.3319\n",
      "Epoch 478/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6265e-04 - val_accuracy: 0.9737 - val_loss: 0.3263\n",
      "Epoch 479/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9688e-06 - val_accuracy: 0.9737 - val_loss: 0.3264\n",
      "Epoch 480/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8027e-05 - val_accuracy: 0.9737 - val_loss: 0.3270\n",
      "Epoch 481/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5609e-06 - val_accuracy: 0.9737 - val_loss: 0.3272\n",
      "Epoch 482/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0746e-04 - val_accuracy: 0.9737 - val_loss: 0.3242\n",
      "Epoch 483/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7259e-06 - val_accuracy: 0.9737 - val_loss: 0.3235\n",
      "Epoch 484/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6262e-05 - val_accuracy: 0.9737 - val_loss: 0.3263\n",
      "Epoch 485/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2555e-05 - val_accuracy: 0.9737 - val_loss: 0.3273\n",
      "Epoch 486/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5471e-06 - val_accuracy: 0.9737 - val_loss: 0.3273\n",
      "Epoch 487/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5691e-06 - val_accuracy: 0.9737 - val_loss: 0.3277\n",
      "Epoch 488/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8175e-05 - val_accuracy: 0.9737 - val_loss: 0.3285\n",
      "Epoch 489/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6831e-05 - val_accuracy: 0.9737 - val_loss: 0.3310\n",
      "Epoch 490/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3253e-05 - val_accuracy: 0.9737 - val_loss: 0.3326\n",
      "Epoch 491/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9881e-06 - val_accuracy: 0.9737 - val_loss: 0.3331\n",
      "Epoch 492/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.2717e-06 - val_accuracy: 0.9737 - val_loss: 0.3341\n",
      "Epoch 493/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6195e-06 - val_accuracy: 0.9737 - val_loss: 0.3368\n",
      "Epoch 494/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8157e-05 - val_accuracy: 0.9737 - val_loss: 0.3379\n",
      "Epoch 495/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4334e-06 - val_accuracy: 0.9737 - val_loss: 0.3364\n",
      "Epoch 496/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2676e-06 - val_accuracy: 0.9737 - val_loss: 0.3366\n",
      "Epoch 497/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9757e-05 - val_accuracy: 0.9737 - val_loss: 0.3357\n",
      "Epoch 498/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.9943e-06 - val_accuracy: 0.9737 - val_loss: 0.3350\n",
      "Epoch 499/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1519e-06 - val_accuracy: 0.9737 - val_loss: 0.3348\n",
      "Epoch 500/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0196e-05 - val_accuracy: 0.9737 - val_loss: 0.3347\n",
      "Epoch 501/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0689e-06 - val_accuracy: 0.9737 - val_loss: 0.3348\n",
      "Epoch 502/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3986e-04 - val_accuracy: 0.9649 - val_loss: 0.3686\n",
      "Epoch 503/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7128e-05 - val_accuracy: 0.9649 - val_loss: 0.3787\n",
      "Epoch 504/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6627e-06 - val_accuracy: 0.9649 - val_loss: 0.3797\n",
      "Epoch 505/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2032e-05 - val_accuracy: 0.9649 - val_loss: 0.3821\n",
      "Epoch 506/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5600e-06 - val_accuracy: 0.9649 - val_loss: 0.3827\n",
      "Epoch 507/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7361e-05 - val_accuracy: 0.9649 - val_loss: 0.3807\n",
      "Epoch 508/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8149e-05 - val_accuracy: 0.9649 - val_loss: 0.3799\n",
      "Epoch 509/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1899e-05 - val_accuracy: 0.9649 - val_loss: 0.3788\n",
      "Epoch 510/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0733e-04 - val_accuracy: 0.9649 - val_loss: 0.3762\n",
      "Epoch 511/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2619e-05 - val_accuracy: 0.9649 - val_loss: 0.3779\n",
      "Epoch 512/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0266e-06 - val_accuracy: 0.9649 - val_loss: 0.3788\n",
      "Epoch 513/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6606e-05 - val_accuracy: 0.9649 - val_loss: 0.3769\n",
      "Epoch 514/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9165e-06 - val_accuracy: 0.9649 - val_loss: 0.3652\n",
      "Epoch 515/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3222e-06 - val_accuracy: 0.9649 - val_loss: 0.3653\n",
      "Epoch 516/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5775e-05 - val_accuracy: 0.9649 - val_loss: 0.3697\n",
      "Epoch 517/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4717e-06 - val_accuracy: 0.9649 - val_loss: 0.3728\n",
      "Epoch 518/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5513e-06 - val_accuracy: 0.9649 - val_loss: 0.3731\n",
      "Epoch 519/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6062e-05 - val_accuracy: 0.9649 - val_loss: 0.3729\n",
      "Epoch 520/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9649 - val_loss: 0.4712\n",
      "Epoch 521/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4929e-04 - val_accuracy: 0.9737 - val_loss: 0.4340\n",
      "Epoch 522/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.0905e-07 - val_accuracy: 0.9737 - val_loss: 0.4221\n",
      "Epoch 523/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4685e-06 - val_accuracy: 0.9737 - val_loss: 0.4211\n",
      "Epoch 524/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0492e-05 - val_accuracy: 0.9737 - val_loss: 0.4161\n",
      "Epoch 525/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.8303e-06 - val_accuracy: 0.9737 - val_loss: 0.4147\n",
      "Epoch 526/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1486e-06 - val_accuracy: 0.9737 - val_loss: 0.4150\n",
      "Epoch 527/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4273e-06 - val_accuracy: 0.9737 - val_loss: 0.4154\n",
      "Epoch 528/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6004e-05 - val_accuracy: 0.9737 - val_loss: 0.4087\n",
      "Epoch 529/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3870e-05 - val_accuracy: 0.9737 - val_loss: 0.3996\n",
      "Epoch 530/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3138e-05 - val_accuracy: 0.9737 - val_loss: 0.3983\n",
      "Epoch 531/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1726e-05 - val_accuracy: 0.9737 - val_loss: 0.4014\n",
      "Epoch 532/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4599e-04 - val_accuracy: 0.9737 - val_loss: 0.4111\n",
      "Epoch 533/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3844e-04 - val_accuracy: 0.9737 - val_loss: 0.3777\n",
      "Epoch 534/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9606e-06 - val_accuracy: 0.9737 - val_loss: 0.3761\n",
      "Epoch 535/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.5088e-06 - val_accuracy: 0.9737 - val_loss: 0.3765\n",
      "Epoch 536/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6379e-06 - val_accuracy: 0.9737 - val_loss: 0.3765\n",
      "Epoch 537/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7775e-05 - val_accuracy: 0.9737 - val_loss: 0.4092\n",
      "Epoch 538/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0194e-05 - val_accuracy: 0.9737 - val_loss: 0.4977\n",
      "Epoch 539/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3514e-05 - val_accuracy: 0.9737 - val_loss: 0.5012\n",
      "Epoch 540/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1315e-06 - val_accuracy: 0.9737 - val_loss: 0.5000\n",
      "Epoch 541/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.9702e-06 - val_accuracy: 0.9737 - val_loss: 0.5025\n",
      "Epoch 542/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4503e-06 - val_accuracy: 0.9737 - val_loss: 0.5033\n",
      "Epoch 543/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7382e-06 - val_accuracy: 0.9737 - val_loss: 0.5045\n",
      "Epoch 544/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6055e-07 - val_accuracy: 0.9737 - val_loss: 0.5048\n",
      "Epoch 545/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5307e-06 - val_accuracy: 0.9737 - val_loss: 0.5051\n",
      "Epoch 546/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0549e-05 - val_accuracy: 0.9737 - val_loss: 0.5061\n",
      "Epoch 547/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6573e-05 - val_accuracy: 0.9737 - val_loss: 0.5097\n",
      "Epoch 548/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4116e-05 - val_accuracy: 0.9737 - val_loss: 0.5082\n",
      "Epoch 549/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3573e-05 - val_accuracy: 0.9737 - val_loss: 0.5060\n",
      "Epoch 550/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3724e-06 - val_accuracy: 0.9737 - val_loss: 0.5061\n",
      "Epoch 551/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.3877e-06 - val_accuracy: 0.9737 - val_loss: 0.5059\n",
      "Epoch 552/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9507e-06 - val_accuracy: 0.9737 - val_loss: 0.5048\n",
      "Epoch 553/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8517e-04 - val_accuracy: 0.9737 - val_loss: 0.5284\n",
      "Epoch 554/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0018 - val_accuracy: 0.9737 - val_loss: 0.3872\n",
      "Epoch 555/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0025 - val_accuracy: 0.9737 - val_loss: 0.2802\n",
      "Epoch 556/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0042 - val_accuracy: 0.9474 - val_loss: 0.4903\n",
      "Epoch 557/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2547e-04 - val_accuracy: 0.9474 - val_loss: 0.4857\n",
      "Epoch 558/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0217e-05 - val_accuracy: 0.9561 - val_loss: 0.4349\n",
      "Epoch 559/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.0486e-06 - val_accuracy: 0.9561 - val_loss: 0.4310\n",
      "Epoch 560/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7071e-04 - val_accuracy: 0.9561 - val_loss: 0.4275\n",
      "Epoch 561/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0038 - val_accuracy: 0.9737 - val_loss: 0.3700\n",
      "Epoch 562/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0437 - val_accuracy: 0.9561 - val_loss: 0.6339\n",
      "Epoch 563/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0568 - val_accuracy: 0.9737 - val_loss: 0.2912\n",
      "Epoch 564/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.9386 - val_loss: 0.4805\n",
      "Epoch 565/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9474 - val_loss: 0.4125\n",
      "Epoch 566/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9461e-04 - val_accuracy: 0.9649 - val_loss: 0.3398\n",
      "Epoch 567/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9561 - val_loss: 0.3277\n",
      "Epoch 568/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.9018e-04 - val_accuracy: 0.9561 - val_loss: 0.4372\n",
      "Epoch 569/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9561 - val_loss: 0.4667\n",
      "Epoch 570/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6825e-04 - val_accuracy: 0.9474 - val_loss: 0.4584\n",
      "Epoch 571/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2575e-04 - val_accuracy: 0.9474 - val_loss: 0.4563\n",
      "Epoch 572/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9915e-04 - val_accuracy: 0.9474 - val_loss: 0.5021\n",
      "Epoch 573/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4392e-04 - val_accuracy: 0.9474 - val_loss: 0.5123\n",
      "Epoch 574/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6778e-04 - val_accuracy: 0.9474 - val_loss: 0.5080\n",
      "Epoch 575/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9509e-04 - val_accuracy: 0.9474 - val_loss: 0.4999\n",
      "Epoch 576/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1602e-04 - val_accuracy: 0.9474 - val_loss: 0.5026\n",
      "Epoch 577/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9006e-05 - val_accuracy: 0.9474 - val_loss: 0.5060\n",
      "Epoch 578/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5410e-04 - val_accuracy: 0.9474 - val_loss: 0.5157\n",
      "Epoch 579/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5441e-05 - val_accuracy: 0.9474 - val_loss: 0.5134\n",
      "Epoch 580/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5152e-04 - val_accuracy: 0.9474 - val_loss: 0.5087\n",
      "Epoch 581/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 9.3677e-04 - val_accuracy: 0.9561 - val_loss: 0.4212\n",
      "Epoch 582/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1166e-04 - val_accuracy: 0.9649 - val_loss: 0.3231\n",
      "Epoch 583/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.1980e-05 - val_accuracy: 0.9649 - val_loss: 0.3130\n",
      "Epoch 584/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9085e-05 - val_accuracy: 0.9649 - val_loss: 0.3181\n",
      "Epoch 585/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6597e-06 - val_accuracy: 0.9649 - val_loss: 0.3194\n",
      "Epoch 586/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9692e-04 - val_accuracy: 0.9649 - val_loss: 0.3311\n",
      "Epoch 587/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0043 - val_accuracy: 0.9561 - val_loss: 0.4761\n",
      "Epoch 588/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0044 - val_accuracy: 0.9737 - val_loss: 0.3362\n",
      "Epoch 589/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9355e-04 - val_accuracy: 0.9737 - val_loss: 0.3459\n",
      "Epoch 590/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.6915e-05 - val_accuracy: 0.9737 - val_loss: 0.3529\n",
      "Epoch 591/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1085e-05 - val_accuracy: 0.9737 - val_loss: 0.3530\n",
      "Epoch 592/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7814e-05 - val_accuracy: 0.9737 - val_loss: 0.3529\n",
      "Epoch 593/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4686e-04 - val_accuracy: 0.9737 - val_loss: 0.3544\n",
      "Epoch 594/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7944e-05 - val_accuracy: 0.9737 - val_loss: 0.3538\n",
      "Epoch 595/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9971e-05 - val_accuracy: 0.9737 - val_loss: 0.3538\n",
      "Epoch 596/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6131e-05 - val_accuracy: 0.9737 - val_loss: 0.3530\n",
      "Epoch 597/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9081e-05 - val_accuracy: 0.9737 - val_loss: 0.3531\n",
      "Epoch 598/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9047e-05 - val_accuracy: 0.9737 - val_loss: 0.3556\n",
      "Epoch 599/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.4816e-06 - val_accuracy: 0.9737 - val_loss: 0.3647\n",
      "Epoch 600/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1737e-04 - val_accuracy: 0.9737 - val_loss: 0.3602\n",
      "Epoch 601/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7625e-05 - val_accuracy: 0.9737 - val_loss: 0.3601\n",
      "Epoch 602/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.3449e-05 - val_accuracy: 0.9737 - val_loss: 0.3627\n",
      "Epoch 603/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8978e-04 - val_accuracy: 0.9649 - val_loss: 0.4850\n",
      "Epoch 604/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9649 - val_loss: 0.5122\n",
      "Epoch 605/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0378e-05 - val_accuracy: 0.9649 - val_loss: 0.5107\n",
      "Epoch 606/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7053e-05 - val_accuracy: 0.9649 - val_loss: 0.5069\n",
      "Epoch 607/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.9649 - val_loss: 0.5196\n",
      "Epoch 608/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0419e-04 - val_accuracy: 0.9386 - val_loss: 0.6415\n",
      "Epoch 609/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9561 - val_loss: 0.5816\n",
      "Epoch 610/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9649 - val_loss: 0.5063\n",
      "Epoch 611/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.0940e-05 - val_accuracy: 0.9561 - val_loss: 0.5113\n",
      "Epoch 612/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.3708e-05 - val_accuracy: 0.9561 - val_loss: 0.4728\n",
      "Epoch 613/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9357e-05 - val_accuracy: 0.9649 - val_loss: 0.4612\n",
      "Epoch 614/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0534e-06 - val_accuracy: 0.9649 - val_loss: 0.4638\n",
      "Epoch 615/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5130e-05 - val_accuracy: 0.9649 - val_loss: 0.4645\n",
      "Epoch 616/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8218e-05 - val_accuracy: 0.9649 - val_loss: 0.4631\n",
      "Epoch 617/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0484e-05 - val_accuracy: 0.9649 - val_loss: 0.4623\n",
      "Epoch 618/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3537e-05 - val_accuracy: 0.9649 - val_loss: 0.4741\n",
      "Epoch 619/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4576e-05 - val_accuracy: 0.9649 - val_loss: 0.4714\n",
      "Epoch 620/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8878e-06 - val_accuracy: 0.9649 - val_loss: 0.4710\n",
      "Epoch 621/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8702e-04 - val_accuracy: 0.9474 - val_loss: 0.5985\n",
      "Epoch 622/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5681e-05 - val_accuracy: 0.9474 - val_loss: 0.6331\n",
      "Epoch 623/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0382e-05 - val_accuracy: 0.9474 - val_loss: 0.6342\n",
      "Epoch 624/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3632e-05 - val_accuracy: 0.9474 - val_loss: 0.6289\n",
      "Epoch 625/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4798e-04 - val_accuracy: 0.9561 - val_loss: 0.5808\n",
      "Epoch 626/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.9375e-06 - val_accuracy: 0.9561 - val_loss: 0.5728\n",
      "Epoch 627/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7958e-05 - val_accuracy: 0.9561 - val_loss: 0.5732\n",
      "Epoch 628/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3184e-05 - val_accuracy: 0.9561 - val_loss: 0.5755\n",
      "Epoch 629/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6061e-04 - val_accuracy: 0.9561 - val_loss: 0.5704\n",
      "Epoch 630/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.1940e-06 - val_accuracy: 0.9561 - val_loss: 0.5694\n",
      "Epoch 631/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3905e-06 - val_accuracy: 0.9561 - val_loss: 0.5710\n",
      "Epoch 632/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9649 - val_loss: 0.4433\n",
      "Epoch 633/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6083e-05 - val_accuracy: 0.9825 - val_loss: 0.3830\n",
      "Epoch 634/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0087 - val_accuracy: 0.9737 - val_loss: 0.4284\n",
      "Epoch 635/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9697e-05 - val_accuracy: 0.9474 - val_loss: 0.6426\n",
      "Epoch 636/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1813e-05 - val_accuracy: 0.9474 - val_loss: 0.6414\n",
      "Epoch 637/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5603e-04 - val_accuracy: 0.9474 - val_loss: 0.6122\n",
      "Epoch 638/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6809e-06 - val_accuracy: 0.9474 - val_loss: 0.6091\n",
      "Epoch 639/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.2726e-04 - val_accuracy: 0.9474 - val_loss: 0.6414\n",
      "Epoch 640/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4774e-04 - val_accuracy: 0.9386 - val_loss: 0.6924\n",
      "Epoch 641/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0081 - val_accuracy: 0.9737 - val_loss: 0.4483\n",
      "Epoch 642/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0838e-04 - val_accuracy: 0.9737 - val_loss: 0.4376\n",
      "Epoch 643/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5951e-05 - val_accuracy: 0.9737 - val_loss: 0.4447\n",
      "Epoch 644/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4419e-04 - val_accuracy: 0.9649 - val_loss: 0.5170\n",
      "Epoch 645/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9040e-07 - val_accuracy: 0.9649 - val_loss: 0.5986\n",
      "Epoch 646/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6303e-04 - val_accuracy: 0.9474 - val_loss: 0.7211\n",
      "Epoch 647/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.6042e-06 - val_accuracy: 0.9474 - val_loss: 0.7580\n",
      "Epoch 648/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8592e-05 - val_accuracy: 0.9474 - val_loss: 0.7603\n",
      "Epoch 649/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3857e-04 - val_accuracy: 0.9474 - val_loss: 0.7932\n",
      "Epoch 650/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1882e-04 - val_accuracy: 0.9474 - val_loss: 0.7765\n",
      "Epoch 651/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7177e-05 - val_accuracy: 0.9474 - val_loss: 0.7637\n",
      "Epoch 652/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4447e-05 - val_accuracy: 0.9474 - val_loss: 0.7754\n",
      "Epoch 653/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4394e-05 - val_accuracy: 0.9474 - val_loss: 0.7779\n",
      "Epoch 654/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0032 - val_accuracy: 0.9649 - val_loss: 0.5462\n",
      "Epoch 655/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3474e-05 - val_accuracy: 0.9649 - val_loss: 0.5402\n",
      "Epoch 656/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0043 - val_accuracy: 0.9649 - val_loss: 0.5154\n",
      "Epoch 657/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0122 - val_accuracy: 0.9649 - val_loss: 0.5228\n",
      "Epoch 658/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3375e-04 - val_accuracy: 0.9649 - val_loss: 0.5745\n",
      "Epoch 659/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5232e-04 - val_accuracy: 0.9649 - val_loss: 0.5778\n",
      "Epoch 660/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.9474 - val_loss: 0.6654\n",
      "Epoch 661/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2252e-04 - val_accuracy: 0.9474 - val_loss: 0.6905\n",
      "Epoch 662/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9561 - val_loss: 0.6106\n",
      "Epoch 663/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0027 - val_accuracy: 0.9561 - val_loss: 0.6192\n",
      "Epoch 664/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.1189e-04 - val_accuracy: 0.9561 - val_loss: 0.6239\n",
      "Epoch 665/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9404e-04 - val_accuracy: 0.9561 - val_loss: 0.6334\n",
      "Epoch 666/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.5107e-04 - val_accuracy: 0.9561 - val_loss: 0.6262\n",
      "Epoch 667/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1521e-04 - val_accuracy: 0.9561 - val_loss: 0.6290\n",
      "Epoch 668/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8805e-04 - val_accuracy: 0.9474 - val_loss: 0.6784\n",
      "Epoch 669/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4719e-04 - val_accuracy: 0.9474 - val_loss: 0.6561\n",
      "Epoch 670/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6127e-05 - val_accuracy: 0.9474 - val_loss: 0.6494\n",
      "Epoch 671/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8013e-05 - val_accuracy: 0.9474 - val_loss: 0.6450\n",
      "Epoch 672/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9474 - val_loss: 0.6661\n",
      "Epoch 673/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.4676e-05 - val_accuracy: 0.9474 - val_loss: 0.6627\n",
      "Epoch 674/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.1591e-04 - val_accuracy: 0.9474 - val_loss: 0.6650\n",
      "Epoch 675/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.3653e-06 - val_accuracy: 0.9474 - val_loss: 0.6623\n",
      "Epoch 676/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.8579e-05 - val_accuracy: 0.9474 - val_loss: 0.6546\n",
      "Epoch 677/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0563e-04 - val_accuracy: 0.9474 - val_loss: 0.6415\n",
      "Epoch 678/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3412e-05 - val_accuracy: 0.9474 - val_loss: 0.6268\n",
      "Epoch 679/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4178e-04 - val_accuracy: 0.9474 - val_loss: 0.6124\n",
      "Epoch 680/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.4326e-06 - val_accuracy: 0.9474 - val_loss: 0.6052\n",
      "Epoch 681/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.5254e-06 - val_accuracy: 0.9474 - val_loss: 0.5989\n",
      "Epoch 682/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.7607e-05 - val_accuracy: 0.9474 - val_loss: 0.5928\n",
      "Epoch 683/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.6217e-06 - val_accuracy: 0.9474 - val_loss: 0.5902\n",
      "Epoch 684/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3173e-05 - val_accuracy: 0.9474 - val_loss: 0.5890\n",
      "Epoch 685/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1542e-04 - val_accuracy: 0.9474 - val_loss: 0.5948\n",
      "Epoch 686/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6663e-05 - val_accuracy: 0.9474 - val_loss: 0.5956\n",
      "Epoch 687/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6143e-06 - val_accuracy: 0.9474 - val_loss: 0.5954\n",
      "Epoch 688/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.2164e-06 - val_accuracy: 0.9474 - val_loss: 0.5954\n",
      "Epoch 689/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8132e-05 - val_accuracy: 0.9474 - val_loss: 0.6070\n",
      "Epoch 690/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9031e-05 - val_accuracy: 0.9474 - val_loss: 0.6122\n",
      "Epoch 691/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0303e-05 - val_accuracy: 0.9474 - val_loss: 0.6121\n",
      "Epoch 692/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5426e-04 - val_accuracy: 0.9474 - val_loss: 0.6015\n",
      "Epoch 693/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.8356e-07 - val_accuracy: 0.9474 - val_loss: 0.6225\n",
      "Epoch 694/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.5745e-05 - val_accuracy: 0.9474 - val_loss: 0.6228\n",
      "Epoch 695/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7003e-05 - val_accuracy: 0.9474 - val_loss: 0.6191\n",
      "Epoch 696/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.4992e-06 - val_accuracy: 0.9474 - val_loss: 0.6178\n",
      "Epoch 697/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.7144e-07 - val_accuracy: 0.9474 - val_loss: 0.6172\n",
      "Epoch 698/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3627e-05 - val_accuracy: 0.9474 - val_loss: 0.6146\n",
      "Epoch 699/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7672e-05 - val_accuracy: 0.9474 - val_loss: 0.6130\n",
      "Epoch 700/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1875e-06 - val_accuracy: 0.9474 - val_loss: 0.6132\n",
      "Epoch 701/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6925e-05 - val_accuracy: 0.9474 - val_loss: 0.6085\n",
      "Epoch 702/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4650e-05 - val_accuracy: 0.9474 - val_loss: 0.5986\n",
      "Epoch 703/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0896e-06 - val_accuracy: 0.9474 - val_loss: 0.5986\n",
      "Epoch 704/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.2862e-06 - val_accuracy: 0.9474 - val_loss: 0.5997\n",
      "Epoch 705/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1135e-04 - val_accuracy: 0.9474 - val_loss: 0.6001\n",
      "Epoch 706/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6079e-05 - val_accuracy: 0.9474 - val_loss: 0.6014\n",
      "Epoch 707/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3549e-05 - val_accuracy: 0.9474 - val_loss: 0.6035\n",
      "Epoch 708/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8751e-05 - val_accuracy: 0.9474 - val_loss: 0.6078\n",
      "Epoch 709/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9327e-06 - val_accuracy: 0.9474 - val_loss: 0.6088\n",
      "Epoch 710/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1201e-06 - val_accuracy: 0.9474 - val_loss: 0.6078\n",
      "Epoch 711/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0400e-05 - val_accuracy: 0.9474 - val_loss: 0.6005\n",
      "Epoch 712/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.7595e-05 - val_accuracy: 0.9474 - val_loss: 0.5839\n",
      "Epoch 713/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6686e-06 - val_accuracy: 0.9474 - val_loss: 0.5871\n",
      "Epoch 714/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2120e-06 - val_accuracy: 0.9474 - val_loss: 0.5967\n",
      "Epoch 715/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.6105e-06 - val_accuracy: 0.9474 - val_loss: 0.5969\n",
      "Epoch 716/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0062e-05 - val_accuracy: 0.9474 - val_loss: 0.6037\n",
      "Epoch 717/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9250e-06 - val_accuracy: 0.9474 - val_loss: 0.6142\n",
      "Epoch 718/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3617e-05 - val_accuracy: 0.9474 - val_loss: 0.6151\n",
      "Epoch 719/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3705e-06 - val_accuracy: 0.9474 - val_loss: 0.6137\n",
      "Epoch 720/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2330e-05 - val_accuracy: 0.9474 - val_loss: 0.6090\n",
      "Epoch 721/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4234e-06 - val_accuracy: 0.9474 - val_loss: 0.6109\n",
      "Epoch 722/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3192e-07 - val_accuracy: 0.9474 - val_loss: 0.6110\n",
      "Epoch 723/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.7709e-06 - val_accuracy: 0.9474 - val_loss: 0.6079\n",
      "Epoch 724/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6999e-05 - val_accuracy: 0.9474 - val_loss: 0.6296\n",
      "Epoch 725/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7891e-05 - val_accuracy: 0.9474 - val_loss: 0.6271\n",
      "Epoch 726/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6201e-06 - val_accuracy: 0.9474 - val_loss: 0.6281\n",
      "Epoch 727/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0660e-05 - val_accuracy: 0.9474 - val_loss: 0.6467\n",
      "Epoch 728/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9153e-06 - val_accuracy: 0.9474 - val_loss: 0.6552\n",
      "Epoch 729/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1885e-05 - val_accuracy: 0.9474 - val_loss: 0.6580\n",
      "Epoch 730/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8761e-06 - val_accuracy: 0.9474 - val_loss: 0.6587\n",
      "Epoch 731/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7677e-05 - val_accuracy: 0.9474 - val_loss: 0.6361\n",
      "Epoch 732/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.2690e-05 - val_accuracy: 0.9474 - val_loss: 0.6220\n",
      "Epoch 733/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6339e-06 - val_accuracy: 0.9474 - val_loss: 0.6197\n",
      "Epoch 734/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.1319e-07 - val_accuracy: 0.9474 - val_loss: 0.6193\n",
      "Epoch 735/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7676e-06 - val_accuracy: 0.9474 - val_loss: 0.6192\n",
      "Epoch 736/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4567e-05 - val_accuracy: 0.9474 - val_loss: 0.6138\n",
      "Epoch 737/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.8859e-06 - val_accuracy: 0.9474 - val_loss: 0.6115\n",
      "Epoch 738/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0002e-05 - val_accuracy: 0.9561 - val_loss: 0.6030\n",
      "Epoch 739/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8811e-06 - val_accuracy: 0.9561 - val_loss: 0.6013\n",
      "Epoch 740/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1172e-07 - val_accuracy: 0.9561 - val_loss: 0.6012\n",
      "Epoch 741/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8891e-05 - val_accuracy: 0.9561 - val_loss: 0.6062\n",
      "Epoch 742/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0724e-05 - val_accuracy: 0.9561 - val_loss: 0.6113\n",
      "Epoch 743/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5180e-06 - val_accuracy: 0.9561 - val_loss: 0.6133\n",
      "Epoch 744/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3405e-06 - val_accuracy: 0.9561 - val_loss: 0.6125\n",
      "Epoch 745/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6319e-06 - val_accuracy: 0.9561 - val_loss: 0.6113\n",
      "Epoch 746/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.6920e-07 - val_accuracy: 0.9561 - val_loss: 0.6124\n",
      "Epoch 747/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8845e-06 - val_accuracy: 0.9561 - val_loss: 0.6064\n",
      "Epoch 748/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2721e-06 - val_accuracy: 0.9561 - val_loss: 0.6040\n",
      "Epoch 749/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1041e-05 - val_accuracy: 0.9561 - val_loss: 0.6142\n",
      "Epoch 750/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2194e-07 - val_accuracy: 0.9561 - val_loss: 0.6202\n",
      "Epoch 751/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1094e-06 - val_accuracy: 0.9561 - val_loss: 0.6192\n",
      "Epoch 752/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6159e-06 - val_accuracy: 0.9561 - val_loss: 0.6162\n",
      "Epoch 753/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6729e-05 - val_accuracy: 0.9561 - val_loss: 0.6124\n",
      "Epoch 754/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4181e-05 - val_accuracy: 0.9474 - val_loss: 0.6642\n",
      "Epoch 755/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2884e-06 - val_accuracy: 0.9474 - val_loss: 0.6770\n",
      "Epoch 756/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.8947e-06 - val_accuracy: 0.9474 - val_loss: 0.6769\n",
      "Epoch 757/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3835e-05 - val_accuracy: 0.9474 - val_loss: 0.7232\n",
      "Epoch 758/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0017e-05 - val_accuracy: 0.9474 - val_loss: 0.7731\n",
      "Epoch 759/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2114e-06 - val_accuracy: 0.9474 - val_loss: 0.7770\n",
      "Epoch 760/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3834e-06 - val_accuracy: 0.9474 - val_loss: 0.7767\n",
      "Epoch 761/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4845e-06 - val_accuracy: 0.9474 - val_loss: 0.7762\n",
      "Epoch 762/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5132e-06 - val_accuracy: 0.9474 - val_loss: 0.7930\n",
      "Epoch 763/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0958e-04 - val_accuracy: 0.9474 - val_loss: 0.7289\n",
      "Epoch 764/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.2320e-06 - val_accuracy: 0.9561 - val_loss: 0.7079\n",
      "Epoch 765/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4356e-07 - val_accuracy: 0.9561 - val_loss: 0.7064\n",
      "Epoch 766/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1182e-05 - val_accuracy: 0.9474 - val_loss: 0.7482\n",
      "Epoch 767/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1344e-05 - val_accuracy: 0.9474 - val_loss: 0.7637\n",
      "Epoch 768/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5151e-07 - val_accuracy: 0.9474 - val_loss: 0.7654\n",
      "Epoch 769/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3345e-06 - val_accuracy: 0.9474 - val_loss: 0.7622\n",
      "Epoch 770/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4895e-07 - val_accuracy: 0.9474 - val_loss: 0.7616\n",
      "Epoch 771/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4142e-07 - val_accuracy: 0.9474 - val_loss: 0.7613\n",
      "Epoch 772/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6567e-06 - val_accuracy: 0.9474 - val_loss: 0.7608\n",
      "Epoch 773/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6958e-06 - val_accuracy: 0.9474 - val_loss: 0.7539\n",
      "Epoch 774/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.6995e-05 - val_accuracy: 0.9474 - val_loss: 0.7487\n",
      "Epoch 775/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.0658e-07 - val_accuracy: 0.9474 - val_loss: 0.7485\n",
      "Epoch 776/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3390e-05 - val_accuracy: 0.9474 - val_loss: 0.7457\n",
      "Epoch 777/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.7910e-07 - val_accuracy: 0.9474 - val_loss: 0.7448\n",
      "Epoch 778/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3901e-05 - val_accuracy: 0.9474 - val_loss: 0.7613\n",
      "Epoch 779/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6002e-07 - val_accuracy: 0.9474 - val_loss: 0.7682\n",
      "Epoch 780/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3345e-06 - val_accuracy: 0.9474 - val_loss: 0.7686\n",
      "Epoch 781/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4836e-06 - val_accuracy: 0.9474 - val_loss: 0.7631\n",
      "Epoch 782/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1068e-06 - val_accuracy: 0.9474 - val_loss: 0.7624\n",
      "Epoch 783/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2527e-07 - val_accuracy: 0.9474 - val_loss: 0.7622\n",
      "Epoch 784/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2473e-04 - val_accuracy: 0.9561 - val_loss: 0.6916\n",
      "Epoch 785/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5906e-06 - val_accuracy: 0.9561 - val_loss: 0.6798\n",
      "Epoch 786/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6372e-08 - val_accuracy: 0.9561 - val_loss: 0.6799\n",
      "Epoch 787/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.7357e-07 - val_accuracy: 0.9561 - val_loss: 0.6796\n",
      "Epoch 788/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.0363e-06 - val_accuracy: 0.9561 - val_loss: 0.6806\n",
      "Epoch 789/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5989e-07 - val_accuracy: 0.9561 - val_loss: 0.6804\n",
      "Epoch 790/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4970e-05 - val_accuracy: 0.9561 - val_loss: 0.7105\n",
      "Epoch 791/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0684e-07 - val_accuracy: 0.9561 - val_loss: 0.7336\n",
      "Epoch 792/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0294e-06 - val_accuracy: 0.9561 - val_loss: 0.7418\n",
      "Epoch 793/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9978e-06 - val_accuracy: 0.9561 - val_loss: 0.7465\n",
      "Epoch 794/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.4450e-07 - val_accuracy: 0.9561 - val_loss: 0.7488\n",
      "Epoch 795/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.2167e-07 - val_accuracy: 0.9561 - val_loss: 0.7492\n",
      "Epoch 796/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6472e-06 - val_accuracy: 0.9561 - val_loss: 0.7478\n",
      "Epoch 797/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0693e-07 - val_accuracy: 0.9561 - val_loss: 0.7471\n",
      "Epoch 798/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6691e-07 - val_accuracy: 0.9561 - val_loss: 0.7466\n",
      "Epoch 799/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8524e-05 - val_accuracy: 0.9561 - val_loss: 0.7539\n",
      "Epoch 800/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4507e-05 - val_accuracy: 0.9474 - val_loss: 0.9087\n",
      "Epoch 801/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.0044e-06 - val_accuracy: 0.9474 - val_loss: 0.9382\n",
      "Epoch 802/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3852e-05 - val_accuracy: 0.9474 - val_loss: 0.9597\n",
      "Epoch 803/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1152e-07 - val_accuracy: 0.9474 - val_loss: 1.0077\n",
      "Epoch 804/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7270e-06 - val_accuracy: 0.9474 - val_loss: 1.0109\n",
      "Epoch 805/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3901e-07 - val_accuracy: 0.9474 - val_loss: 1.0108\n",
      "Epoch 806/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8321e-06 - val_accuracy: 0.9474 - val_loss: 1.0068\n",
      "Epoch 807/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.0058e-04 - val_accuracy: 0.9561 - val_loss: 0.8251\n",
      "Epoch 808/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8364e-07 - val_accuracy: 0.9561 - val_loss: 0.8160\n",
      "Epoch 809/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6104e-06 - val_accuracy: 0.9561 - val_loss: 0.8113\n",
      "Epoch 810/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6921e-06 - val_accuracy: 0.9561 - val_loss: 0.8164\n",
      "Epoch 811/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6434e-06 - val_accuracy: 0.9561 - val_loss: 0.8168\n",
      "Epoch 812/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0231e-07 - val_accuracy: 0.9561 - val_loss: 0.8157\n",
      "Epoch 813/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0026 - val_accuracy: 0.9211 - val_loss: 1.8832\n",
      "Epoch 814/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0174 - val_accuracy: 0.9474 - val_loss: 0.9154\n",
      "Epoch 815/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.9474 - val_loss: 1.1360\n",
      "Epoch 816/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0126 - val_accuracy: 0.8947 - val_loss: 1.2544\n",
      "Epoch 817/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7376e-04 - val_accuracy: 0.9298 - val_loss: 0.7871\n",
      "Epoch 818/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5276e-04 - val_accuracy: 0.9561 - val_loss: 0.7316\n",
      "Epoch 819/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9969 - loss: 0.0057 - val_accuracy: 0.9649 - val_loss: 0.5733\n",
      "Epoch 820/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7020e-04 - val_accuracy: 0.9649 - val_loss: 0.5746\n",
      "Epoch 821/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2646e-04 - val_accuracy: 0.9649 - val_loss: 0.6182\n",
      "Epoch 822/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.5372e-05 - val_accuracy: 0.9649 - val_loss: 0.6066\n",
      "Epoch 823/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8025e-04 - val_accuracy: 0.9649 - val_loss: 0.5955\n",
      "Epoch 824/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6024e-05 - val_accuracy: 0.9649 - val_loss: 0.5948\n",
      "Epoch 825/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9064e-04 - val_accuracy: 0.9649 - val_loss: 0.7747\n",
      "Epoch 826/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0053 - val_accuracy: 0.9737 - val_loss: 0.6029\n",
      "Epoch 827/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0136 - val_accuracy: 0.9649 - val_loss: 0.5202\n",
      "Epoch 828/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.9386 - val_loss: 1.1181\n",
      "Epoch 829/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.8299e-04 - val_accuracy: 0.9298 - val_loss: 1.3154\n",
      "Epoch 830/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.0139 - val_accuracy: 0.9561 - val_loss: 0.7452\n",
      "Epoch 831/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1664e-05 - val_accuracy: 0.9561 - val_loss: 0.6830\n",
      "Epoch 832/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.3836e-05 - val_accuracy: 0.9561 - val_loss: 0.6766\n",
      "Epoch 833/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6210e-04 - val_accuracy: 0.9561 - val_loss: 0.6755\n",
      "Epoch 834/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.0448e-04 - val_accuracy: 0.9474 - val_loss: 0.8018\n",
      "Epoch 835/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4238e-05 - val_accuracy: 0.9386 - val_loss: 0.8742\n",
      "Epoch 836/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3751e-05 - val_accuracy: 0.9386 - val_loss: 0.8908\n",
      "Epoch 837/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4688e-05 - val_accuracy: 0.9386 - val_loss: 0.9004\n",
      "Epoch 838/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5875e-05 - val_accuracy: 0.9386 - val_loss: 0.9006\n",
      "Epoch 839/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0618e-05 - val_accuracy: 0.9386 - val_loss: 0.8941\n",
      "Epoch 840/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.2568e-05 - val_accuracy: 0.9386 - val_loss: 0.8755\n",
      "Epoch 841/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 7.3243e-04 - val_accuracy: 0.9474 - val_loss: 0.7966\n",
      "Epoch 842/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.1977e-06 - val_accuracy: 0.9561 - val_loss: 0.7548\n",
      "Epoch 843/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.8219e-05 - val_accuracy: 0.9561 - val_loss: 0.7587\n",
      "Epoch 844/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6612e-05 - val_accuracy: 0.9561 - val_loss: 0.7633\n",
      "Epoch 845/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.5174e-05 - val_accuracy: 0.9561 - val_loss: 0.7645\n",
      "Epoch 846/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.7511e-04 - val_accuracy: 0.9561 - val_loss: 0.7428\n",
      "Epoch 847/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.4916e-06 - val_accuracy: 0.9561 - val_loss: 0.7187\n",
      "Epoch 848/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.4421e-05 - val_accuracy: 0.9561 - val_loss: 0.7231\n",
      "Epoch 849/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3545e-05 - val_accuracy: 0.9561 - val_loss: 0.7332\n",
      "Epoch 850/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.8339e-05 - val_accuracy: 0.9561 - val_loss: 0.7334\n",
      "Epoch 851/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 7.0435e-04 - val_accuracy: 0.9474 - val_loss: 0.9245\n",
      "Epoch 852/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.8052e-05 - val_accuracy: 0.9211 - val_loss: 1.1452\n",
      "Epoch 853/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2439e-04 - val_accuracy: 0.9211 - val_loss: 1.1401\n",
      "Epoch 854/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0084e-05 - val_accuracy: 0.9211 - val_loss: 1.1287\n",
      "Epoch 855/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0013 - val_accuracy: 0.9386 - val_loss: 0.9609\n",
      "Epoch 856/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5985e-04 - val_accuracy: 0.9474 - val_loss: 0.9215\n",
      "Epoch 857/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 9.2826e-04 - val_accuracy: 0.9474 - val_loss: 0.9510\n",
      "Epoch 858/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 7.3674e-04 - val_accuracy: 0.9386 - val_loss: 0.9425\n",
      "Epoch 859/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1649e-04 - val_accuracy: 0.9561 - val_loss: 0.8064\n",
      "Epoch 860/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.7612e-04 - val_accuracy: 0.9649 - val_loss: 0.6560\n",
      "Epoch 861/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0389e-04 - val_accuracy: 0.9561 - val_loss: 0.8288\n",
      "Epoch 862/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0120e-04 - val_accuracy: 0.9386 - val_loss: 0.9476\n",
      "Epoch 863/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2943e-04 - val_accuracy: 0.9386 - val_loss: 1.0020\n",
      "Epoch 864/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9474 - val_loss: 0.9495\n",
      "Epoch 865/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.1252e-06 - val_accuracy: 0.9561 - val_loss: 0.9424\n",
      "Epoch 866/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2794e-04 - val_accuracy: 0.9561 - val_loss: 0.9394\n",
      "Epoch 867/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9042e-05 - val_accuracy: 0.9561 - val_loss: 0.9385\n",
      "Epoch 868/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 1.2304e-05 - val_accuracy: 0.9561 - val_loss: 0.9384\n",
      "Epoch 869/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8456e-04 - val_accuracy: 0.9474 - val_loss: 0.9571\n",
      "Epoch 870/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.5838e-06 - val_accuracy: 0.9474 - val_loss: 0.9588\n",
      "Epoch 871/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3008e-04 - val_accuracy: 0.9649 - val_loss: 0.9020\n",
      "Epoch 872/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0078 - val_accuracy: 0.9474 - val_loss: 1.0785\n",
      "Epoch 873/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9454e-05 - val_accuracy: 0.9561 - val_loss: 0.9387\n",
      "Epoch 874/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0654e-05 - val_accuracy: 0.9561 - val_loss: 0.9219\n",
      "Epoch 875/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.9740e-06 - val_accuracy: 0.9561 - val_loss: 0.9198\n",
      "Epoch 876/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6582e-05 - val_accuracy: 0.9561 - val_loss: 0.9238\n",
      "Epoch 877/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0029 - val_accuracy: 0.9649 - val_loss: 0.8358\n",
      "Epoch 878/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1582e-06 - val_accuracy: 0.9649 - val_loss: 0.7153\n",
      "Epoch 879/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0092 - val_accuracy: 0.9649 - val_loss: 0.8429\n",
      "Epoch 880/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9794e-05 - val_accuracy: 0.9561 - val_loss: 0.8992\n",
      "Epoch 881/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.8944e-06 - val_accuracy: 0.9561 - val_loss: 0.9020\n",
      "Epoch 882/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.4824e-05 - val_accuracy: 0.9561 - val_loss: 0.8947\n",
      "Epoch 883/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.0283e-05 - val_accuracy: 0.9649 - val_loss: 0.8809\n",
      "Epoch 884/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4493e-04 - val_accuracy: 0.9649 - val_loss: 0.8844\n",
      "Epoch 885/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6246e-05 - val_accuracy: 0.9649 - val_loss: 0.8973\n",
      "Epoch 886/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9649 - val_loss: 0.7961\n",
      "Epoch 887/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4749e-04 - val_accuracy: 0.9649 - val_loss: 0.8439\n",
      "Epoch 888/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4956e-05 - val_accuracy: 0.9386 - val_loss: 1.1372\n",
      "Epoch 889/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.3739e-04 - val_accuracy: 0.9474 - val_loss: 1.0687\n",
      "Epoch 890/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.4988e-05 - val_accuracy: 0.9561 - val_loss: 1.0084\n",
      "Epoch 891/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1181e-05 - val_accuracy: 0.9561 - val_loss: 1.0018\n",
      "Epoch 892/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.6851e-05 - val_accuracy: 0.9561 - val_loss: 0.9694\n",
      "Epoch 893/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0020 - val_accuracy: 0.9649 - val_loss: 0.6733\n",
      "Epoch 894/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9649 - val_loss: 0.8545\n",
      "Epoch 895/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.9150e-05 - val_accuracy: 0.9474 - val_loss: 1.0654\n",
      "Epoch 896/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9474 - val_loss: 1.0022\n",
      "Epoch 897/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.1656e-05 - val_accuracy: 0.9561 - val_loss: 0.9809\n",
      "Epoch 898/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9649 - val_loss: 0.8458\n",
      "Epoch 899/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9649 - val_loss: 0.6683\n",
      "Epoch 900/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1879e-04 - val_accuracy: 0.9649 - val_loss: 0.6604\n",
      "Epoch 901/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9470e-04 - val_accuracy: 0.9649 - val_loss: 0.6963\n",
      "Epoch 902/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.7179e-05 - val_accuracy: 0.9649 - val_loss: 0.6975\n",
      "Epoch 903/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3107e-05 - val_accuracy: 0.9649 - val_loss: 0.6981\n",
      "Epoch 904/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6705e-05 - val_accuracy: 0.9649 - val_loss: 0.7003\n",
      "Epoch 905/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 4.6346e-04 - val_accuracy: 0.9649 - val_loss: 0.7233\n",
      "Epoch 906/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0692e-05 - val_accuracy: 0.9561 - val_loss: 0.7679\n",
      "Epoch 907/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4336e-06 - val_accuracy: 0.9561 - val_loss: 0.7717\n",
      "Epoch 908/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.8698e-05 - val_accuracy: 0.9561 - val_loss: 0.7704\n",
      "Epoch 909/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4920e-06 - val_accuracy: 0.9561 - val_loss: 0.7698\n",
      "Epoch 910/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8894e-05 - val_accuracy: 0.9561 - val_loss: 0.7739\n",
      "Epoch 911/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6206e-04 - val_accuracy: 0.9561 - val_loss: 0.7751\n",
      "Epoch 912/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.7240e-05 - val_accuracy: 0.9649 - val_loss: 0.7755\n",
      "Epoch 913/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7773e-05 - val_accuracy: 0.9649 - val_loss: 0.7746\n",
      "Epoch 914/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.9855e-04 - val_accuracy: 0.9649 - val_loss: 0.7457\n",
      "Epoch 915/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7767e-05 - val_accuracy: 0.9649 - val_loss: 0.7397\n",
      "Epoch 916/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0015e-05 - val_accuracy: 0.9649 - val_loss: 0.7391\n",
      "Epoch 917/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.7665e-06 - val_accuracy: 0.9649 - val_loss: 0.7393\n",
      "Epoch 918/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6189e-06 - val_accuracy: 0.9649 - val_loss: 0.7391\n",
      "Epoch 919/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 7.8684e-04 - val_accuracy: 0.9561 - val_loss: 0.8309\n",
      "Epoch 920/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.3441e-06 - val_accuracy: 0.9386 - val_loss: 1.1060\n",
      "Epoch 921/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0726e-05 - val_accuracy: 0.9386 - val_loss: 1.1317\n",
      "Epoch 922/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0026 - val_accuracy: 0.9561 - val_loss: 0.8611\n",
      "Epoch 923/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3375e-05 - val_accuracy: 0.9561 - val_loss: 0.8208\n",
      "Epoch 924/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6966e-05 - val_accuracy: 0.9561 - val_loss: 0.8249\n",
      "Epoch 925/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9987e-05 - val_accuracy: 0.9561 - val_loss: 0.8278\n",
      "Epoch 926/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.5626e-06 - val_accuracy: 0.9561 - val_loss: 0.8284\n",
      "Epoch 927/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0204 - val_accuracy: 0.9386 - val_loss: 1.0956\n",
      "Epoch 928/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.9386 - val_loss: 0.9727\n",
      "Epoch 929/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8774e-06 - val_accuracy: 0.9386 - val_loss: 0.9395\n",
      "Epoch 930/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0420e-05 - val_accuracy: 0.9386 - val_loss: 0.9368\n",
      "Epoch 931/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3068e-06 - val_accuracy: 0.9386 - val_loss: 0.9375\n",
      "Epoch 932/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0219e-05 - val_accuracy: 0.9386 - val_loss: 0.9366\n",
      "Epoch 933/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.4654e-06 - val_accuracy: 0.9386 - val_loss: 0.9360\n",
      "Epoch 934/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8035e-04 - val_accuracy: 0.9386 - val_loss: 1.0514\n",
      "Epoch 935/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9510e-04 - val_accuracy: 0.9386 - val_loss: 1.0571\n",
      "Epoch 936/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.0673e-05 - val_accuracy: 0.9386 - val_loss: 1.0563\n",
      "Epoch 937/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2445e-05 - val_accuracy: 0.9386 - val_loss: 1.0459\n",
      "Epoch 938/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.1294e-05 - val_accuracy: 0.9386 - val_loss: 1.0409\n",
      "Epoch 939/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0797e-04 - val_accuracy: 0.9474 - val_loss: 0.9715\n",
      "Epoch 940/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9055e-06 - val_accuracy: 0.9474 - val_loss: 0.9267\n",
      "Epoch 941/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7707e-06 - val_accuracy: 0.9474 - val_loss: 0.9227\n",
      "Epoch 942/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4883e-04 - val_accuracy: 0.9474 - val_loss: 1.0289\n",
      "Epoch 943/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4025e-05 - val_accuracy: 0.9474 - val_loss: 1.0985\n",
      "Epoch 944/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8075e-06 - val_accuracy: 0.9474 - val_loss: 1.1039\n",
      "Epoch 945/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.0074e-05 - val_accuracy: 0.9474 - val_loss: 1.1077\n",
      "Epoch 946/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.2907e-05 - val_accuracy: 0.9474 - val_loss: 1.1088\n",
      "Epoch 947/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0421e-06 - val_accuracy: 0.9474 - val_loss: 1.1110\n",
      "Epoch 948/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8817e-06 - val_accuracy: 0.9474 - val_loss: 1.1116\n",
      "Epoch 949/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.5084e-06 - val_accuracy: 0.9474 - val_loss: 1.1126\n",
      "Epoch 950/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 8.8681e-06 - val_accuracy: 0.9474 - val_loss: 1.1120\n",
      "Epoch 951/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.0436e-05 - val_accuracy: 0.9474 - val_loss: 1.1101\n",
      "Epoch 952/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1106e-05 - val_accuracy: 0.9474 - val_loss: 1.1080\n",
      "Epoch 953/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9087e-05 - val_accuracy: 0.9474 - val_loss: 1.1061\n",
      "Epoch 954/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.4064e-06 - val_accuracy: 0.9474 - val_loss: 1.1057\n",
      "Epoch 955/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.2175e-05 - val_accuracy: 0.9474 - val_loss: 1.1052\n",
      "Epoch 956/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.8959e-06 - val_accuracy: 0.9474 - val_loss: 1.1051\n",
      "Epoch 957/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.9455e-05 - val_accuracy: 0.9474 - val_loss: 1.1101\n",
      "Epoch 958/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.7079e-04 - val_accuracy: 0.9474 - val_loss: 1.0922\n",
      "Epoch 959/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.3202e-07 - val_accuracy: 0.9474 - val_loss: 1.0787\n",
      "Epoch 960/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.6419e-06 - val_accuracy: 0.9474 - val_loss: 1.0803\n",
      "Epoch 961/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.7088e-05 - val_accuracy: 0.9474 - val_loss: 1.0848\n",
      "Epoch 962/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9474 - val_loss: 0.9162\n",
      "Epoch 963/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.8725e-06 - val_accuracy: 0.9474 - val_loss: 0.8956\n",
      "Epoch 964/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.6526e-04 - val_accuracy: 0.9474 - val_loss: 0.8558\n",
      "Epoch 965/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3751e-07 - val_accuracy: 0.9474 - val_loss: 0.8507\n",
      "Epoch 966/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.8031e-05 - val_accuracy: 0.9474 - val_loss: 0.8527\n",
      "Epoch 967/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9073e-06 - val_accuracy: 0.9474 - val_loss: 0.8728\n",
      "Epoch 968/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 6.4909e-04 - val_accuracy: 0.9474 - val_loss: 0.9833\n",
      "Epoch 969/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.7996e-04 - val_accuracy: 0.9474 - val_loss: 1.0901\n",
      "Epoch 970/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5464e-04 - val_accuracy: 0.9474 - val_loss: 1.0457\n",
      "Epoch 971/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.5098e-06 - val_accuracy: 0.9474 - val_loss: 1.0533\n",
      "Epoch 972/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1402e-04 - val_accuracy: 0.9474 - val_loss: 0.9609\n",
      "Epoch 973/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.7172e-05 - val_accuracy: 0.9561 - val_loss: 0.9264\n",
      "Epoch 974/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6895e-05 - val_accuracy: 0.9561 - val_loss: 0.9221\n",
      "Epoch 975/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0569e-05 - val_accuracy: 0.9561 - val_loss: 0.9215\n",
      "Epoch 976/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9024e-05 - val_accuracy: 0.9561 - val_loss: 0.9230\n",
      "Epoch 977/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1364e-06 - val_accuracy: 0.9561 - val_loss: 0.9231\n",
      "Epoch 978/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1837e-07 - val_accuracy: 0.9561 - val_loss: 0.9231\n",
      "Epoch 979/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.8462e-05 - val_accuracy: 0.9561 - val_loss: 0.9237\n",
      "Epoch 980/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.0399e-06 - val_accuracy: 0.9561 - val_loss: 0.9269\n",
      "Epoch 981/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6598e-07 - val_accuracy: 0.9561 - val_loss: 0.9271\n",
      "Epoch 982/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.5875e-06 - val_accuracy: 0.9561 - val_loss: 0.9272\n",
      "Epoch 983/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.3453e-04 - val_accuracy: 0.9561 - val_loss: 0.9199\n",
      "Epoch 984/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.7256e-07 - val_accuracy: 0.9561 - val_loss: 0.9148\n",
      "Epoch 985/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5363e-05 - val_accuracy: 0.9561 - val_loss: 0.9237\n",
      "Epoch 986/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3409e-04 - val_accuracy: 0.9561 - val_loss: 0.9791\n",
      "Epoch 987/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1628e-04 - val_accuracy: 0.9561 - val_loss: 0.9761\n",
      "Epoch 988/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3104e-06 - val_accuracy: 0.9561 - val_loss: 0.9758\n",
      "Epoch 989/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.1748e-04 - val_accuracy: 0.9561 - val_loss: 0.9578\n",
      "Epoch 990/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 9.1070e-07 - val_accuracy: 0.9561 - val_loss: 0.9508\n",
      "Epoch 991/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1325e-05 - val_accuracy: 0.9561 - val_loss: 0.9426\n",
      "Epoch 992/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1580e-07 - val_accuracy: 0.9561 - val_loss: 0.9380\n",
      "Epoch 993/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 4.3374e-06 - val_accuracy: 0.9561 - val_loss: 0.9383\n",
      "Epoch 994/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1124e-07 - val_accuracy: 0.9561 - val_loss: 0.9384\n",
      "Epoch 995/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6053e-06 - val_accuracy: 0.9561 - val_loss: 0.9380\n",
      "Epoch 996/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.6124e-06 - val_accuracy: 0.9561 - val_loss: 0.9378\n",
      "Epoch 997/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9871e-07 - val_accuracy: 0.9561 - val_loss: 0.9377\n",
      "Epoch 998/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.4488e-08 - val_accuracy: 0.9561 - val_loss: 0.9378\n",
      "Epoch 999/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8108e-07 - val_accuracy: 0.9561 - val_loss: 0.9378\n",
      "Epoch 1000/1000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.0518e-06 - val_accuracy: 0.9561 - val_loss: 0.9381\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9595 - loss: 0.6913 \n",
      "Test Accuracy: 0.9561\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy and precision score are:\n",
      "Accuracy Score: 0.956140\n",
      "Precision Score: 1.000000\n",
      "Recall score :0.943182\n",
      "[[26  0]\n",
      " [ 5 83]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score,confusion_matrix,recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Convert to DataFrame\n",
    "data_table = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "data_table['target'] = data.target\n",
    "\n",
    "print(data_table)\n",
    "\n",
    "X = data_table.drop(columns=['target'])  # Select all feature columns\n",
    "y = data_table['target']  # Target variable\n",
    "\n",
    "split = int(len(data_table) * 0.8)\n",
    "x_train = X.iloc[:split]\n",
    "y_train = y.iloc[:split]\n",
    "x_test = X.iloc[split:]\n",
    "y_test = y.iloc[split:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)  # Only transform test data, not fit\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128,input_dim=x_train.shape[1],activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=1000,batch_size=20,validation_data=(x_test,y_test))\n",
    "\n",
    "loss,accuracy = model.evaluate(x_test,y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred,axis=1)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred_classes)\n",
    "pre_score = precision_score(y_test, y_pred_classes, average='binary')\n",
    "rec_score = recall_score(y_test,y_pred_classes)\n",
    "matrix = confusion_matrix(y_test,y_pred_classes)\n",
    "\n",
    "\n",
    "print('The accuracy and precision score are:')\n",
    "print(f\"Accuracy Score: {acc_score:2f}\")\n",
    "print(f\"Precision Score: {pre_score:2f}\")\n",
    "print(f\"Recall score :{rec_score:2f}\")\n",
    "print(matrix)\n",
    "\n",
    "model.save('cancer_detection_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
